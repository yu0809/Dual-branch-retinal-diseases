{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom torchvision import models\nfrom sklearn.preprocessing import LabelEncoder\nimport os\n\n# 设置随机种子以确保可重复性\ndef set_seed(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# 数据集类\nclass NPYDataset(Dataset):\n    def __init__(self, csv_file, root_dir):\n        try:\n            self.annotations = pd.read_csv(csv_file, encoding='utf-8')\n        except UnicodeDecodeError:\n            self.annotations = pd.read_csv(csv_file, encoding='gbk')\n        self.root_dir = root_dir\n        self.le = LabelEncoder()\n        self.annotations['labels'] = self.annotations['labels'].apply(lambda x: x.strip(\"[]'\"))\n        self.annotations['labels'] = self.le.fit_transform(self.annotations['labels'])\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_name = os.path.join(self.root_dir, str(self.annotations.iloc[index, -1]) + '.npy')\n        image = np.load(img_name)\n        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n        label = self.annotations.iloc[index, 2]\n        return image, label\n\n# 模型定义\nclass DenseNet2D(nn.Module):\n    def __init__(self, num_classes):\n        super(DenseNet2D, self).__init__()\n        # 使用预训练的DenseNet模型\n        self.densenet = models.densenet121(pretrained=True)\n        self.dropout = nn.Dropout(0.5)  # 添加Dropout层\n        \n        # DenseNet的分类器部分是一个名为classifier的线性层\n        # 我们需要用新的线性层替换它，以匹配我们的类别数目\n        self.densenet.classifier = nn.Linear(self.densenet.classifier.in_features, num_classes)\n        \n        # 由于我们已经在上面的行中将原始的分类器替换掉了，\n        # 所以这里不需要再替换fc层为Identity\n\n    def forward(self, x):\n        # 通过DenseNet模型\n        x = self.densenet(x)\n        # Dropout层现在不是必需的，因为我们在最后一层之前已经包含了dropout\n        # x = self.dropout(x)\n        # 由于我们已经将分类器层替换为自定义的线性层，以下步骤也不再需要\n        # x = self.fc(x)\n        return x\n\n# 训练和评估参数\nnum_epochs = 10\nbatch_size = 16\nlearning_rate = 0.0005\n\n# 设备配置\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 数据加载\ntrain_dataset = NPYDataset(csv_file='/kaggle/input/gaus-d-n/train.csv', root_dir='/kaggle/input/gaus-d-n/normalized_gaus_train_images/normalized_gaus_train_images')\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n\nvalidation_dataset = NPYDataset(csv_file='/kaggle/input/gaus-d-n/validation.csv', root_dir='/kaggle/input/gaus-d-n/normalized_gaus_validation_images/normalized_gaus_validation_images')\nvalidation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n\ntest_dataset = NPYDataset(csv_file='/kaggle/input/gaus-d-n/test.csv', root_dir='/kaggle/input/gaus-d-n/normalized_gaus_test_images/normalized_gaus_test_images')\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n# 模型初始化\nnum_classes = len(np.unique(train_dataset.annotations['labels']))\n\n# 创建一个权重数组\n# 这里假设类别标签已经编码为0, 1\nweights = torch.tensor([1.0, 1.0], dtype=torch.float32).to(device)\n\n# 使用加权损失函数\ncriterion = nn.CrossEntropyLoss(weight=weights)\n\nmodel = DenseNet2D(num_classes=num_classes).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-1)  # 增加权重衰减\n\n# 学习率调度器\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n# 训练模型的代码...\n# 请根据您的具体需求添加训练循环和验证/测试循环","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:31:15.619585Z","iopub.execute_input":"2024-03-21T14:31:15.619948Z","iopub.status.idle":"2024-03-21T14:31:26.911344Z","shell.execute_reply.started":"2024-03-21T14:31:15.619917Z","shell.execute_reply":"2024-03-21T14:31:26.910239Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 104MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# 确保模型在GPU上\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# 确保模型处于训练模式\nmodel.train()\n\n# 可能需要调整学习率\n#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)  # 示例学习率\n\nfor epoch in range(0, 20):  # 继续训练过程\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).long()\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # 每个epoch结束后打印损失\n    print(f'Epoch [{epoch+1}/{20}], Loss: {loss.item():.4f}')\n    \n    # 每个epoch结束后在训练集上评估模型\n    model.eval()  # 切换到评估模式\n    with torch.no_grad():\n        train_preds = []\n        train_labels = []\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            train_preds.extend(predicted.view(-1).cpu().numpy())\n            train_labels.extend(labels.view(-1).cpu().numpy())\n        train_accuracy = 100 * np.sum(np.array(train_preds) == np.array(train_labels)) / len(train_labels)\n        print(f'Train Accuracy: {train_accuracy:.2f} %')\n\n    # 每个epoch结束后在验证集上评估模型\n    with torch.no_grad():\n        val_preds = []\n        val_labels = []\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            val_preds.extend(predicted.view(-1).cpu().numpy())\n            val_labels.extend(labels.view(-1).cpu().numpy())\n        val_accuracy = 100 * np.sum(np.array(val_preds) == np.array(val_labels)) / len(val_labels)\n        print(f'Validation Accuracy: {val_accuracy:.2f} %')\n    \n    # 每个epoch结束后在测试集上评估模型\n    with torch.no_grad():\n        test_preds = []\n        test_labels = []\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            test_preds.extend(predicted.view(-1).cpu().numpy())\n            test_labels.extend(labels.view(-1).cpu().numpy())\n    \n        test_accuracy = 100 * np.sum(np.array(test_preds) == np.array(test_labels)) / len(test_labels)\n        print(f'Test Accuracy: {test_accuracy:.2f} %')\n\n        # 计算精确率、召回率和F1分数\n        precision = precision_score(test_labels, test_preds, average='weighted')\n        recall = recall_score(test_labels, test_preds, average='weighted')\n        f1 = f1_score(test_labels, test_preds, average='weighted')\n    \n        print(f'Precision: {precision:.4f}')\n        print(f'Recall: {recall:.4f}')\n        print(f'F1 Score: {f1:.4f}')\n    \n    model.train()  # 切换回训练模式","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:31:26.913646Z","iopub.execute_input":"2024-03-21T14:31:26.914023Z","iopub.status.idle":"2024-03-21T14:42:49.233509Z","shell.execute_reply.started":"2024-03-21T14:31:26.913992Z","shell.execute_reply":"2024-03-21T14:42:49.231950Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch [1/20], Loss: 0.4563\nTrain Accuracy: 69.43 %\nValidation Accuracy: 64.67 %\nTest Accuracy: 68.00 %\nPrecision: 0.7498\nRecall: 0.6800\nF1 Score: 0.6541\nEpoch [2/20], Loss: 0.3066\nTrain Accuracy: 72.57 %\nValidation Accuracy: 64.00 %\nTest Accuracy: 66.67 %\nPrecision: 0.7408\nRecall: 0.6667\nF1 Score: 0.6367\nEpoch [3/20], Loss: 0.3816\nTrain Accuracy: 93.29 %\nValidation Accuracy: 80.00 %\nTest Accuracy: 82.00 %\nPrecision: 0.8200\nRecall: 0.8200\nF1 Score: 0.8200\nEpoch [4/20], Loss: 0.6082\nTrain Accuracy: 93.57 %\nValidation Accuracy: 74.00 %\nTest Accuracy: 81.33 %\nPrecision: 0.8379\nRecall: 0.8133\nF1 Score: 0.8103\nEpoch [5/20], Loss: 0.6895\nTrain Accuracy: 94.43 %\nValidation Accuracy: 71.33 %\nTest Accuracy: 78.00 %\nPrecision: 0.8157\nRecall: 0.7800\nF1 Score: 0.7742\nEpoch [6/20], Loss: 0.0756\nTrain Accuracy: 98.86 %\nValidation Accuracy: 82.00 %\nTest Accuracy: 82.00 %\nPrecision: 0.8200\nRecall: 0.8200\nF1 Score: 0.8200\nEpoch [7/20], Loss: 0.0742\nTrain Accuracy: 98.00 %\nValidation Accuracy: 78.67 %\nTest Accuracy: 80.67 %\nPrecision: 0.8071\nRecall: 0.8067\nF1 Score: 0.8065\nEpoch [8/20], Loss: 0.0176\nTrain Accuracy: 92.86 %\nValidation Accuracy: 74.67 %\nTest Accuracy: 74.67 %\nPrecision: 0.7794\nRecall: 0.7467\nF1 Score: 0.7382\nEpoch [9/20], Loss: 0.0573\nTrain Accuracy: 96.43 %\nValidation Accuracy: 71.33 %\nTest Accuracy: 80.67 %\nPrecision: 0.8228\nRecall: 0.8067\nF1 Score: 0.8038\nEpoch [10/20], Loss: 0.0046\nTrain Accuracy: 97.00 %\nValidation Accuracy: 74.67 %\nTest Accuracy: 83.33 %\nPrecision: 0.8347\nRecall: 0.8333\nF1 Score: 0.8331\nEpoch [11/20], Loss: 0.0231\nTrain Accuracy: 99.14 %\nValidation Accuracy: 77.33 %\nTest Accuracy: 81.33 %\nPrecision: 0.8219\nRecall: 0.8133\nF1 Score: 0.8123\nEpoch [12/20], Loss: 0.3278\nTrain Accuracy: 91.86 %\nValidation Accuracy: 72.00 %\nTest Accuracy: 77.33 %\nPrecision: 0.7983\nRecall: 0.7733\nF1 Score: 0.7679\nEpoch [13/20], Loss: 0.1723\nTrain Accuracy: 87.57 %\nValidation Accuracy: 70.00 %\nTest Accuracy: 75.33 %\nPrecision: 0.8247\nRecall: 0.7533\nF1 Score: 0.7400\nEpoch [14/20], Loss: 0.0657\nTrain Accuracy: 99.71 %\nValidation Accuracy: 74.00 %\nTest Accuracy: 81.33 %\nPrecision: 0.8330\nRecall: 0.8133\nF1 Score: 0.8109\nEpoch [15/20], Loss: 0.0017\nTrain Accuracy: 100.00 %\nValidation Accuracy: 77.33 %\nTest Accuracy: 87.33 %\nPrecision: 0.8768\nRecall: 0.8733\nF1 Score: 0.8731\nEpoch [16/20], Loss: 0.0059\nTrain Accuracy: 100.00 %\nValidation Accuracy: 76.67 %\nTest Accuracy: 85.33 %\nPrecision: 0.8664\nRecall: 0.8533\nF1 Score: 0.8522\nEpoch [17/20], Loss: 0.0149\nTrain Accuracy: 100.00 %\nValidation Accuracy: 77.33 %\nTest Accuracy: 86.00 %\nPrecision: 0.8753\nRecall: 0.8600\nF1 Score: 0.8588\nEpoch [18/20], Loss: 0.0011\nTrain Accuracy: 100.00 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 86.00 %\nPrecision: 0.8714\nRecall: 0.8600\nF1 Score: 0.8591\nEpoch [19/20], Loss: 0.2821\nTrain Accuracy: 100.00 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 86.67 %\nPrecision: 0.8766\nRecall: 0.8667\nF1 Score: 0.8660\nEpoch [20/20], Loss: 0.3631\nTrain Accuracy: 96.86 %\nValidation Accuracy: 69.33 %\nTest Accuracy: 80.00 %\nPrecision: 0.8075\nRecall: 0.8000\nF1 Score: 0.7985\n","output_type":"stream"}]}]}