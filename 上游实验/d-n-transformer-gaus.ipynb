{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7972266,"datasetId":4658595,"databundleVersionId":8082490}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import timm\nimport torch.nn as nn\n\nclass SwinTransformer2D(nn.Module):\n    def __init__(self, num_classes):\n        super(SwinTransformer2D, self).__init__()\n        self.swin_transformer = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=num_classes)\n\n    def forward(self, x):\n        x = self.swin_transformer(x)\n        return x\n\nmodel = SwinTransformer2D(num_classes=1000)\n\n# 打印所有层的名称\nprint(\"所有层的名称:\")\nfor name, module in model.named_modules():\n    print(name)\n\n# 找到并打印最后两层的名称\nlayer_names = [name for name, _ in model.named_modules()]\nif len(layer_names) >= 2:\n    print(\"\\n最后两层的名称:\")\n    print(layer_names[-2:])\nelse:\n    print(\"模型中没有足够的层来显示最后两层的名称\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:43:48.610491Z","iopub.execute_input":"2024-04-05T06:43:48.611117Z","iopub.status.idle":"2024-04-05T06:44:17.540103Z","shell.execute_reply.started":"2024-04-05T06:43:48.611083Z","shell.execute_reply":"2024-04-05T06:44:17.539140Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cebdc2a8906b4547b8ea30014f6807f7"}},"metadata":{}},{"name":"stdout","text":"所有层的名称:\n\nswin_transformer\nswin_transformer.patch_embed\nswin_transformer.patch_embed.proj\nswin_transformer.patch_embed.norm\nswin_transformer.layers\nswin_transformer.layers.0\nswin_transformer.layers.0.downsample\nswin_transformer.layers.0.blocks\nswin_transformer.layers.0.blocks.0\nswin_transformer.layers.0.blocks.0.norm1\nswin_transformer.layers.0.blocks.0.attn\nswin_transformer.layers.0.blocks.0.attn.qkv\nswin_transformer.layers.0.blocks.0.attn.attn_drop\nswin_transformer.layers.0.blocks.0.attn.proj\nswin_transformer.layers.0.blocks.0.attn.proj_drop\nswin_transformer.layers.0.blocks.0.attn.softmax\nswin_transformer.layers.0.blocks.0.drop_path1\nswin_transformer.layers.0.blocks.0.norm2\nswin_transformer.layers.0.blocks.0.mlp\nswin_transformer.layers.0.blocks.0.mlp.fc1\nswin_transformer.layers.0.blocks.0.mlp.act\nswin_transformer.layers.0.blocks.0.mlp.drop1\nswin_transformer.layers.0.blocks.0.mlp.norm\nswin_transformer.layers.0.blocks.0.mlp.fc2\nswin_transformer.layers.0.blocks.0.mlp.drop2\nswin_transformer.layers.0.blocks.0.drop_path2\nswin_transformer.layers.0.blocks.1\nswin_transformer.layers.0.blocks.1.norm1\nswin_transformer.layers.0.blocks.1.attn\nswin_transformer.layers.0.blocks.1.attn.qkv\nswin_transformer.layers.0.blocks.1.attn.attn_drop\nswin_transformer.layers.0.blocks.1.attn.proj\nswin_transformer.layers.0.blocks.1.attn.proj_drop\nswin_transformer.layers.0.blocks.1.attn.softmax\nswin_transformer.layers.0.blocks.1.drop_path1\nswin_transformer.layers.0.blocks.1.norm2\nswin_transformer.layers.0.blocks.1.mlp\nswin_transformer.layers.0.blocks.1.mlp.fc1\nswin_transformer.layers.0.blocks.1.mlp.act\nswin_transformer.layers.0.blocks.1.mlp.drop1\nswin_transformer.layers.0.blocks.1.mlp.norm\nswin_transformer.layers.0.blocks.1.mlp.fc2\nswin_transformer.layers.0.blocks.1.mlp.drop2\nswin_transformer.layers.0.blocks.1.drop_path2\nswin_transformer.layers.1\nswin_transformer.layers.1.downsample\nswin_transformer.layers.1.downsample.norm\nswin_transformer.layers.1.downsample.reduction\nswin_transformer.layers.1.blocks\nswin_transformer.layers.1.blocks.0\nswin_transformer.layers.1.blocks.0.norm1\nswin_transformer.layers.1.blocks.0.attn\nswin_transformer.layers.1.blocks.0.attn.qkv\nswin_transformer.layers.1.blocks.0.attn.attn_drop\nswin_transformer.layers.1.blocks.0.attn.proj\nswin_transformer.layers.1.blocks.0.attn.proj_drop\nswin_transformer.layers.1.blocks.0.attn.softmax\nswin_transformer.layers.1.blocks.0.drop_path1\nswin_transformer.layers.1.blocks.0.norm2\nswin_transformer.layers.1.blocks.0.mlp\nswin_transformer.layers.1.blocks.0.mlp.fc1\nswin_transformer.layers.1.blocks.0.mlp.act\nswin_transformer.layers.1.blocks.0.mlp.drop1\nswin_transformer.layers.1.blocks.0.mlp.norm\nswin_transformer.layers.1.blocks.0.mlp.fc2\nswin_transformer.layers.1.blocks.0.mlp.drop2\nswin_transformer.layers.1.blocks.0.drop_path2\nswin_transformer.layers.1.blocks.1\nswin_transformer.layers.1.blocks.1.norm1\nswin_transformer.layers.1.blocks.1.attn\nswin_transformer.layers.1.blocks.1.attn.qkv\nswin_transformer.layers.1.blocks.1.attn.attn_drop\nswin_transformer.layers.1.blocks.1.attn.proj\nswin_transformer.layers.1.blocks.1.attn.proj_drop\nswin_transformer.layers.1.blocks.1.attn.softmax\nswin_transformer.layers.1.blocks.1.drop_path1\nswin_transformer.layers.1.blocks.1.norm2\nswin_transformer.layers.1.blocks.1.mlp\nswin_transformer.layers.1.blocks.1.mlp.fc1\nswin_transformer.layers.1.blocks.1.mlp.act\nswin_transformer.layers.1.blocks.1.mlp.drop1\nswin_transformer.layers.1.blocks.1.mlp.norm\nswin_transformer.layers.1.blocks.1.mlp.fc2\nswin_transformer.layers.1.blocks.1.mlp.drop2\nswin_transformer.layers.1.blocks.1.drop_path2\nswin_transformer.layers.2\nswin_transformer.layers.2.downsample\nswin_transformer.layers.2.downsample.norm\nswin_transformer.layers.2.downsample.reduction\nswin_transformer.layers.2.blocks\nswin_transformer.layers.2.blocks.0\nswin_transformer.layers.2.blocks.0.norm1\nswin_transformer.layers.2.blocks.0.attn\nswin_transformer.layers.2.blocks.0.attn.qkv\nswin_transformer.layers.2.blocks.0.attn.attn_drop\nswin_transformer.layers.2.blocks.0.attn.proj\nswin_transformer.layers.2.blocks.0.attn.proj_drop\nswin_transformer.layers.2.blocks.0.attn.softmax\nswin_transformer.layers.2.blocks.0.drop_path1\nswin_transformer.layers.2.blocks.0.norm2\nswin_transformer.layers.2.blocks.0.mlp\nswin_transformer.layers.2.blocks.0.mlp.fc1\nswin_transformer.layers.2.blocks.0.mlp.act\nswin_transformer.layers.2.blocks.0.mlp.drop1\nswin_transformer.layers.2.blocks.0.mlp.norm\nswin_transformer.layers.2.blocks.0.mlp.fc2\nswin_transformer.layers.2.blocks.0.mlp.drop2\nswin_transformer.layers.2.blocks.0.drop_path2\nswin_transformer.layers.2.blocks.1\nswin_transformer.layers.2.blocks.1.norm1\nswin_transformer.layers.2.blocks.1.attn\nswin_transformer.layers.2.blocks.1.attn.qkv\nswin_transformer.layers.2.blocks.1.attn.attn_drop\nswin_transformer.layers.2.blocks.1.attn.proj\nswin_transformer.layers.2.blocks.1.attn.proj_drop\nswin_transformer.layers.2.blocks.1.attn.softmax\nswin_transformer.layers.2.blocks.1.drop_path1\nswin_transformer.layers.2.blocks.1.norm2\nswin_transformer.layers.2.blocks.1.mlp\nswin_transformer.layers.2.blocks.1.mlp.fc1\nswin_transformer.layers.2.blocks.1.mlp.act\nswin_transformer.layers.2.blocks.1.mlp.drop1\nswin_transformer.layers.2.blocks.1.mlp.norm\nswin_transformer.layers.2.blocks.1.mlp.fc2\nswin_transformer.layers.2.blocks.1.mlp.drop2\nswin_transformer.layers.2.blocks.1.drop_path2\nswin_transformer.layers.2.blocks.2\nswin_transformer.layers.2.blocks.2.norm1\nswin_transformer.layers.2.blocks.2.attn\nswin_transformer.layers.2.blocks.2.attn.qkv\nswin_transformer.layers.2.blocks.2.attn.attn_drop\nswin_transformer.layers.2.blocks.2.attn.proj\nswin_transformer.layers.2.blocks.2.attn.proj_drop\nswin_transformer.layers.2.blocks.2.attn.softmax\nswin_transformer.layers.2.blocks.2.drop_path1\nswin_transformer.layers.2.blocks.2.norm2\nswin_transformer.layers.2.blocks.2.mlp\nswin_transformer.layers.2.blocks.2.mlp.fc1\nswin_transformer.layers.2.blocks.2.mlp.act\nswin_transformer.layers.2.blocks.2.mlp.drop1\nswin_transformer.layers.2.blocks.2.mlp.norm\nswin_transformer.layers.2.blocks.2.mlp.fc2\nswin_transformer.layers.2.blocks.2.mlp.drop2\nswin_transformer.layers.2.blocks.2.drop_path2\nswin_transformer.layers.2.blocks.3\nswin_transformer.layers.2.blocks.3.norm1\nswin_transformer.layers.2.blocks.3.attn\nswin_transformer.layers.2.blocks.3.attn.qkv\nswin_transformer.layers.2.blocks.3.attn.attn_drop\nswin_transformer.layers.2.blocks.3.attn.proj\nswin_transformer.layers.2.blocks.3.attn.proj_drop\nswin_transformer.layers.2.blocks.3.attn.softmax\nswin_transformer.layers.2.blocks.3.drop_path1\nswin_transformer.layers.2.blocks.3.norm2\nswin_transformer.layers.2.blocks.3.mlp\nswin_transformer.layers.2.blocks.3.mlp.fc1\nswin_transformer.layers.2.blocks.3.mlp.act\nswin_transformer.layers.2.blocks.3.mlp.drop1\nswin_transformer.layers.2.blocks.3.mlp.norm\nswin_transformer.layers.2.blocks.3.mlp.fc2\nswin_transformer.layers.2.blocks.3.mlp.drop2\nswin_transformer.layers.2.blocks.3.drop_path2\nswin_transformer.layers.2.blocks.4\nswin_transformer.layers.2.blocks.4.norm1\nswin_transformer.layers.2.blocks.4.attn\nswin_transformer.layers.2.blocks.4.attn.qkv\nswin_transformer.layers.2.blocks.4.attn.attn_drop\nswin_transformer.layers.2.blocks.4.attn.proj\nswin_transformer.layers.2.blocks.4.attn.proj_drop\nswin_transformer.layers.2.blocks.4.attn.softmax\nswin_transformer.layers.2.blocks.4.drop_path1\nswin_transformer.layers.2.blocks.4.norm2\nswin_transformer.layers.2.blocks.4.mlp\nswin_transformer.layers.2.blocks.4.mlp.fc1\nswin_transformer.layers.2.blocks.4.mlp.act\nswin_transformer.layers.2.blocks.4.mlp.drop1\nswin_transformer.layers.2.blocks.4.mlp.norm\nswin_transformer.layers.2.blocks.4.mlp.fc2\nswin_transformer.layers.2.blocks.4.mlp.drop2\nswin_transformer.layers.2.blocks.4.drop_path2\nswin_transformer.layers.2.blocks.5\nswin_transformer.layers.2.blocks.5.norm1\nswin_transformer.layers.2.blocks.5.attn\nswin_transformer.layers.2.blocks.5.attn.qkv\nswin_transformer.layers.2.blocks.5.attn.attn_drop\nswin_transformer.layers.2.blocks.5.attn.proj\nswin_transformer.layers.2.blocks.5.attn.proj_drop\nswin_transformer.layers.2.blocks.5.attn.softmax\nswin_transformer.layers.2.blocks.5.drop_path1\nswin_transformer.layers.2.blocks.5.norm2\nswin_transformer.layers.2.blocks.5.mlp\nswin_transformer.layers.2.blocks.5.mlp.fc1\nswin_transformer.layers.2.blocks.5.mlp.act\nswin_transformer.layers.2.blocks.5.mlp.drop1\nswin_transformer.layers.2.blocks.5.mlp.norm\nswin_transformer.layers.2.blocks.5.mlp.fc2\nswin_transformer.layers.2.blocks.5.mlp.drop2\nswin_transformer.layers.2.blocks.5.drop_path2\nswin_transformer.layers.3\nswin_transformer.layers.3.downsample\nswin_transformer.layers.3.downsample.norm\nswin_transformer.layers.3.downsample.reduction\nswin_transformer.layers.3.blocks\nswin_transformer.layers.3.blocks.0\nswin_transformer.layers.3.blocks.0.norm1\nswin_transformer.layers.3.blocks.0.attn\nswin_transformer.layers.3.blocks.0.attn.qkv\nswin_transformer.layers.3.blocks.0.attn.attn_drop\nswin_transformer.layers.3.blocks.0.attn.proj\nswin_transformer.layers.3.blocks.0.attn.proj_drop\nswin_transformer.layers.3.blocks.0.attn.softmax\nswin_transformer.layers.3.blocks.0.drop_path1\nswin_transformer.layers.3.blocks.0.norm2\nswin_transformer.layers.3.blocks.0.mlp\nswin_transformer.layers.3.blocks.0.mlp.fc1\nswin_transformer.layers.3.blocks.0.mlp.act\nswin_transformer.layers.3.blocks.0.mlp.drop1\nswin_transformer.layers.3.blocks.0.mlp.norm\nswin_transformer.layers.3.blocks.0.mlp.fc2\nswin_transformer.layers.3.blocks.0.mlp.drop2\nswin_transformer.layers.3.blocks.0.drop_path2\nswin_transformer.layers.3.blocks.1\nswin_transformer.layers.3.blocks.1.norm1\nswin_transformer.layers.3.blocks.1.attn\nswin_transformer.layers.3.blocks.1.attn.qkv\nswin_transformer.layers.3.blocks.1.attn.attn_drop\nswin_transformer.layers.3.blocks.1.attn.proj\nswin_transformer.layers.3.blocks.1.attn.proj_drop\nswin_transformer.layers.3.blocks.1.attn.softmax\nswin_transformer.layers.3.blocks.1.drop_path1\nswin_transformer.layers.3.blocks.1.norm2\nswin_transformer.layers.3.blocks.1.mlp\nswin_transformer.layers.3.blocks.1.mlp.fc1\nswin_transformer.layers.3.blocks.1.mlp.act\nswin_transformer.layers.3.blocks.1.mlp.drop1\nswin_transformer.layers.3.blocks.1.mlp.norm\nswin_transformer.layers.3.blocks.1.mlp.fc2\nswin_transformer.layers.3.blocks.1.mlp.drop2\nswin_transformer.layers.3.blocks.1.drop_path2\nswin_transformer.norm\nswin_transformer.head\nswin_transformer.head.global_pool\nswin_transformer.head.global_pool.pool\nswin_transformer.head.global_pool.flatten\nswin_transformer.head.drop\nswin_transformer.head.fc\nswin_transformer.head.flatten\n\n最后两层的名称:\n['swin_transformer.head.fc', 'swin_transformer.head.flatten']\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport os\nimport timm\nfrom torchvision import transforms\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchvision.transforms.functional import to_tensor, normalize\n\n# 设置随机种子以确保可重复性\ndef set_seed(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# 数据集类\nclass NPYDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        try:\n            self.annotations = pd.read_csv(csv_file, encoding='utf-8')\n        except UnicodeDecodeError:\n            self.annotations = pd.read_csv(csv_file, encoding='gbk')\n        self.root_dir = root_dir\n        self.le = LabelEncoder()\n        self.annotations['labels'] = self.annotations['labels'].apply(lambda x: x.strip(\"[]'\"))\n        self.annotations['labels'] = self.le.fit_transform(self.annotations['labels'])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_name = os.path.join(self.root_dir, str(self.annotations.iloc[index, -1]) + '.npy')\n        image = np.load(img_name).astype(np.float32)  # 将数据类型转换为float32\n        if self.transform:\n            image = self.transform(image)\n        label = self.annotations.iloc[index, 2]\n        return image, label\n\n\n# 定义图像转换\ntransform = transforms.Compose([\n    transforms.ToTensor(),  # 将numpy数组转换为torch张量，并且从(H, W, C)转换为(C, H, W)且归一化到[0, 1]\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n])\n\n# 模型定义\nclass SwinTransformer2D(nn.Module):\n    def __init__(self, num_classes):\n        super(SwinTransformer2D, self).__init__()\n        self.swin_transformer = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=num_classes)\n\n    def forward(self, x):\n        x = self.swin_transformer(x)\n        return x\n\n# 训练和评估参数\nnum_epochs = 47\nbatch_size = 32\nlearning_rate = 0.001\n\n# 设备配置\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 数据加载\ntrain_dataset = NPYDataset(csv_file='/kaggle/input/d-n-transformer/train.csv', root_dir='/kaggle/input/d-n-transformer/transformer_gaus_train/transformer_gaus_train', transform=transform)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n\nvalidation_dataset = NPYDataset(csv_file='/kaggle/input/d-n-transformer/validation.csv', root_dir='/kaggle/input/d-n-transformer/transformer_gaus_validation/transformer_gaus_validation', transform=transform)\nvalidation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n\ntest_dataset = NPYDataset(csv_file='/kaggle/input/d-n-transformer/test.csv', root_dir='/kaggle/input/d-n-transformer/transformer_gaus_test/transformer_gaus_test', transform=transform)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n# 模型初始化\nnum_classes = len(np.unique(train_dataset.annotations['labels']))\nmodel = SwinTransformer2D(num_classes=num_classes).to(device)\n\n# 创建一个权重数组，给第三类更高的权重\nweights = torch.tensor([1.0, 1.0], dtype=torch.float32).to(device)\n\n# 使用加权损失函数\ncriterion = nn.CrossEntropyLoss(weight=weights)\n\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-2)\n\n# 学习率调度器\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:44:17.542209Z","iopub.execute_input":"2024-04-05T06:44:17.542717Z","iopub.status.idle":"2024-04-05T06:44:20.626428Z","shell.execute_reply.started":"2024-04-05T06:44:17.542680Z","shell.execute_reply":"2024-04-05T06:44:20.625628Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# 评估函数\ndef evaluate_model(model, data_loader, device='cuda'):\n    model.eval()  # 设置模型为评估模式\n    total = 0\n    correct = 0\n    with torch.no_grad():\n        for images, labels in data_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    return accuracy\n\ndef train_model(model, train_loader, validation_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n    # 解冻最后两层的参数\n    for name, param in model.named_parameters():\n        if 'head' in name or 'swin_transformer.norm'in name or 'swin_transformer.layers.3.blocks.1.drop_path2' in name:  # 根据层的名称来解冻\n            param.requires_grad = True\n        else:\n            param.requires_grad = False\n    \n    # 确保优化器仅更新requires_grad=True的参数\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n    \n    for epoch in range(num_epochs):\n        model.train()  # 设置模型为训练模式\n        running_loss = 0.0\n        \n        # 训练过程\n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        scheduler.step()\n\n        # 在每个epoch结束后评估模型性能\n        train_accuracy = evaluate_model(model, train_loader, device)\n        validation_accuracy = evaluate_model(model, validation_loader, device)\n        test_accuracy = evaluate_model(model, test_loader, device)\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n              f'Train Accuracy: {train_accuracy:.2f}%, '\n              f'Validation Accuracy: {validation_accuracy:.2f}%, '\n              f'Test Accuracy: {test_accuracy:.2f}%')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:44:20.627576Z","iopub.execute_input":"2024-04-05T06:44:20.627832Z","iopub.status.idle":"2024-04-05T06:44:20.641452Z","shell.execute_reply.started":"2024-04-05T06:44:20.627810Z","shell.execute_reply":"2024-04-05T06:44:20.640648Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 开始训练模型\ntrain_model(model, train_loader, validation_loader, test_loader, criterion, optimizer, scheduler, num_epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:44:20.643662Z","iopub.execute_input":"2024-04-05T06:44:20.643941Z","iopub.status.idle":"2024-04-05T06:50:17.216468Z","shell.execute_reply.started":"2024-04-05T06:44:20.643902Z","shell.execute_reply":"2024-04-05T06:50:17.215546Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/47], Loss: 0.6766, Train Accuracy: 66.71%, Validation Accuracy: 64.00%, Test Accuracy: 61.33%\nEpoch [2/47], Loss: 0.6350, Train Accuracy: 59.86%, Validation Accuracy: 58.67%, Test Accuracy: 60.00%\nEpoch [3/47], Loss: 0.6057, Train Accuracy: 71.57%, Validation Accuracy: 64.00%, Test Accuracy: 73.33%\nEpoch [4/47], Loss: 0.5952, Train Accuracy: 71.57%, Validation Accuracy: 65.33%, Test Accuracy: 73.33%\nEpoch [5/47], Loss: 0.5709, Train Accuracy: 73.43%, Validation Accuracy: 70.00%, Test Accuracy: 70.67%\nEpoch [6/47], Loss: 0.5691, Train Accuracy: 73.86%, Validation Accuracy: 65.33%, Test Accuracy: 73.33%\nEpoch [7/47], Loss: 0.5525, Train Accuracy: 75.29%, Validation Accuracy: 68.67%, Test Accuracy: 75.33%\nEpoch [8/47], Loss: 0.5462, Train Accuracy: 74.57%, Validation Accuracy: 68.67%, Test Accuracy: 72.67%\nEpoch [9/47], Loss: 0.5439, Train Accuracy: 74.57%, Validation Accuracy: 65.33%, Test Accuracy: 75.33%\nEpoch [10/47], Loss: 0.5205, Train Accuracy: 73.43%, Validation Accuracy: 73.33%, Test Accuracy: 70.00%\nEpoch [11/47], Loss: 0.5308, Train Accuracy: 75.57%, Validation Accuracy: 73.33%, Test Accuracy: 73.33%\nEpoch [12/47], Loss: 0.5227, Train Accuracy: 77.00%, Validation Accuracy: 72.67%, Test Accuracy: 74.00%\nEpoch [13/47], Loss: 0.5035, Train Accuracy: 75.29%, Validation Accuracy: 72.67%, Test Accuracy: 69.33%\nEpoch [14/47], Loss: 0.4915, Train Accuracy: 78.00%, Validation Accuracy: 72.67%, Test Accuracy: 76.67%\nEpoch [15/47], Loss: 0.5080, Train Accuracy: 77.00%, Validation Accuracy: 72.00%, Test Accuracy: 74.67%\nEpoch [16/47], Loss: 0.5148, Train Accuracy: 79.14%, Validation Accuracy: 72.00%, Test Accuracy: 74.67%\nEpoch [17/47], Loss: 0.5050, Train Accuracy: 78.29%, Validation Accuracy: 70.67%, Test Accuracy: 75.33%\nEpoch [18/47], Loss: 0.5016, Train Accuracy: 76.71%, Validation Accuracy: 74.67%, Test Accuracy: 72.67%\nEpoch [19/47], Loss: 0.5020, Train Accuracy: 77.43%, Validation Accuracy: 72.67%, Test Accuracy: 74.00%\nEpoch [20/47], Loss: 0.4802, Train Accuracy: 79.71%, Validation Accuracy: 72.00%, Test Accuracy: 74.67%\nEpoch [21/47], Loss: 0.4761, Train Accuracy: 79.43%, Validation Accuracy: 72.67%, Test Accuracy: 75.33%\nEpoch [22/47], Loss: 0.4797, Train Accuracy: 75.29%, Validation Accuracy: 76.67%, Test Accuracy: 72.67%\nEpoch [23/47], Loss: 0.4910, Train Accuracy: 80.71%, Validation Accuracy: 73.33%, Test Accuracy: 75.33%\nEpoch [24/47], Loss: 0.4723, Train Accuracy: 80.00%, Validation Accuracy: 70.67%, Test Accuracy: 78.00%\nEpoch [25/47], Loss: 0.4820, Train Accuracy: 80.86%, Validation Accuracy: 74.00%, Test Accuracy: 75.33%\nEpoch [26/47], Loss: 0.4688, Train Accuracy: 80.71%, Validation Accuracy: 72.00%, Test Accuracy: 78.67%\nEpoch [27/47], Loss: 0.4678, Train Accuracy: 81.14%, Validation Accuracy: 71.33%, Test Accuracy: 78.67%\nEpoch [28/47], Loss: 0.4695, Train Accuracy: 81.57%, Validation Accuracy: 72.00%, Test Accuracy: 78.67%\nEpoch [29/47], Loss: 0.4838, Train Accuracy: 80.29%, Validation Accuracy: 74.67%, Test Accuracy: 74.67%\nEpoch [30/47], Loss: 0.4561, Train Accuracy: 81.00%, Validation Accuracy: 74.00%, Test Accuracy: 74.67%\nEpoch [31/47], Loss: 0.4592, Train Accuracy: 81.71%, Validation Accuracy: 72.67%, Test Accuracy: 76.00%\nEpoch [32/47], Loss: 0.4538, Train Accuracy: 81.29%, Validation Accuracy: 74.67%, Test Accuracy: 74.67%\nEpoch [33/47], Loss: 0.4851, Train Accuracy: 80.29%, Validation Accuracy: 70.00%, Test Accuracy: 76.67%\nEpoch [34/47], Loss: 0.4545, Train Accuracy: 82.43%, Validation Accuracy: 72.67%, Test Accuracy: 78.00%\nEpoch [35/47], Loss: 0.4488, Train Accuracy: 83.00%, Validation Accuracy: 72.00%, Test Accuracy: 78.67%\nEpoch [36/47], Loss: 0.4608, Train Accuracy: 77.29%, Validation Accuracy: 68.00%, Test Accuracy: 77.33%\nEpoch [37/47], Loss: 0.4595, Train Accuracy: 78.14%, Validation Accuracy: 66.00%, Test Accuracy: 75.33%\nEpoch [38/47], Loss: 0.4424, Train Accuracy: 80.14%, Validation Accuracy: 69.33%, Test Accuracy: 78.67%\nEpoch [39/47], Loss: 0.4603, Train Accuracy: 82.86%, Validation Accuracy: 70.67%, Test Accuracy: 78.67%\nEpoch [40/47], Loss: 0.4336, Train Accuracy: 83.29%, Validation Accuracy: 71.33%, Test Accuracy: 80.67%\nEpoch [41/47], Loss: 0.4339, Train Accuracy: 84.00%, Validation Accuracy: 72.00%, Test Accuracy: 78.67%\nEpoch [42/47], Loss: 0.4464, Train Accuracy: 82.86%, Validation Accuracy: 74.00%, Test Accuracy: 77.33%\nEpoch [43/47], Loss: 0.4387, Train Accuracy: 84.00%, Validation Accuracy: 74.00%, Test Accuracy: 79.33%\nEpoch [44/47], Loss: 0.4267, Train Accuracy: 80.71%, Validation Accuracy: 70.00%, Test Accuracy: 79.33%\nEpoch [45/47], Loss: 0.4424, Train Accuracy: 83.86%, Validation Accuracy: 74.00%, Test Accuracy: 78.00%\nEpoch [46/47], Loss: 0.4361, Train Accuracy: 83.86%, Validation Accuracy: 74.00%, Test Accuracy: 76.00%\nEpoch [47/47], Loss: 0.4186, Train Accuracy: 84.57%, Validation Accuracy: 73.33%, Test Accuracy: 80.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"# 保存模型权重\nmodel_path = '/kaggle/working/trained_model.pth'  # 指定模型保存路径\ntorch.save(model.state_dict(), model_path)  # 保存模型权重","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:50:17.217876Z","iopub.execute_input":"2024-04-05T06:50:17.218542Z","iopub.status.idle":"2024-04-05T06:50:17.375686Z","shell.execute_reply.started":"2024-04-05T06:50:17.218506Z","shell.execute_reply":"2024-04-05T06:50:17.374854Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 正确的类别数，根据错误消息，应该是2\nnum_classes = 2\n\n# 使用正确的类别数创建模型实例\nmodel = SwinTransformer2D(num_classes=num_classes)\n\n# 现在加载模型应该不会出错，因为类别数匹配\nmodel.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n\n# 根据你的需要调用 model.train() 或 model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:50:17.377035Z","iopub.execute_input":"2024-04-05T06:50:17.377347Z","iopub.status.idle":"2024-04-05T06:50:18.394407Z","shell.execute_reply.started":"2024-04-05T06:50:17.377322Z","shell.execute_reply":"2024-04-05T06:50:18.393547Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"import torch  \nimport numpy as np  \nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score  \n  \n# 假设model, test_loader, device等都已正确定义和初始化  \nmodel = model.to(device)\nmodel.eval()  \nwith torch.no_grad():  \n    all_preds = []  \n    all_labels = []  \n    for images, labels in test_loader:  \n        images, labels = images.to(device), labels.to(device).long()  \n        outputs = model(images)  \n        _, predicted = torch.max(outputs.data, 1)  \n          \n        # 收集所有预测和标签  \n        all_preds.extend(predicted.view(-1).cpu().numpy())  \n        all_labels.extend(labels.view(-1).cpu().numpy())  \n  \n    # 计算准确率  \n    accuracy = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)  \n    print(f'Accuracy of the model on the test images: {accuracy:.2f} %')  \n      \n    # 计算精确率、召回率和F1分数  \n    precision = precision_score(all_labels, all_preds, average='weighted')  \n    recall = recall_score(all_labels, all_preds, average='weighted')  \n    f1 = f1_score(all_labels, all_preds, average='weighted')  \n      \n    print(f'Precision: {precision:.4f}')  \n    print(f'Recall: {recall:.4f}')  \n    print(f'F1 Score: {f1:.4f}')  \n  \n    # 计算混淆矩阵  \n    cm = confusion_matrix(all_labels, all_preds)  \n      \n    # 计算每个类别的准确率  \n    class_accuracy = cm.diagonal() / cm.sum(axis=1)  \n      \n    # 打印每个类别的准确率  \n    for i in range(len(class_accuracy)):  \n        print(f'Accuracy for class {i}: {class_accuracy[i]:.2f}')  \n  \n# 打印所有预测结果（如果需要）  \n# print('All Predictions:', all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:50:18.395563Z","iopub.execute_input":"2024-04-05T06:50:18.395840Z","iopub.status.idle":"2024-04-05T06:50:19.168739Z","shell.execute_reply.started":"2024-04-05T06:50:18.395817Z","shell.execute_reply":"2024-04-05T06:50:19.167759Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Accuracy of the model on the test images: 80.00 %\nPrecision: 0.8003\nRecall: 0.8000\nF1 Score: 0.8000\nAccuracy for class 0: 0.79\nAccuracy for class 1: 0.81\n","output_type":"stream"}]},{"cell_type":"code","source":"# 打印所有预测结果\nprint('All Predictions:', all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:50:19.169807Z","iopub.execute_input":"2024-04-05T06:50:19.170074Z","iopub.status.idle":"2024-04-05T06:50:19.175159Z","shell.execute_reply.started":"2024-04-05T06:50:19.170044Z","shell.execute_reply":"2024-04-05T06:50:19.174205Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"All Predictions: [0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming `le` is your LabelEncoder instance that has been fitted to the labels\nprint(\"Label mapping:\")\nfor i, label in enumerate(train_dataset.le.classes_):\n    print(f\"{label}: {i}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T06:50:19.176415Z","iopub.execute_input":"2024-04-05T06:50:19.176832Z","iopub.status.idle":"2024-04-05T06:50:19.186958Z","shell.execute_reply.started":"2024-04-05T06:50:19.176807Z","shell.execute_reply":"2024-04-05T06:50:19.186134Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Label mapping:\nD: 0\nN: 1\n","output_type":"stream"}]},{"cell_type":"code","source":"# 初始化一个空列表来存储预测错误的索引\nerror_indices = []\n\n# 遍历所有预测和标签，比较它们是否相等\nfor idx, (pred, label) in enumerate(zip(all_preds, all_labels)):\n    if pred != label:\n        # 如果预测不等于标签，记录该实例的索引\n        error_indices.append(idx)\n\n# 输出预测错误的实例索引\nprint(\"预测错误的实例索引:\", error_indices)\n\n# 如果您想查看预测错误的详细信息，可以按以下方式打印每个错误实例的预测值和真实值\nfor error_index in error_indices:\n    print(f'实例 {error_index} 错误预测为 {all_preds[error_index]}，实际标签为 {all_labels[error_index]}')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T07:41:09.078803Z","iopub.execute_input":"2024-03-29T07:41:09.079602Z","iopub.status.idle":"2024-03-29T07:41:09.086302Z","shell.execute_reply.started":"2024-03-29T07:41:09.079558Z","shell.execute_reply":"2024-03-29T07:41:09.0854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# 给定的行号列表，已经转换为Python的索引（从0开始）\nrows = [24, 34, 38, 39, 50, 57, 71, 72, 73, 86, 121, 130, 136, 141, 145, 178, 186, 193, 195, 197, 198, 200, 204, 205, 212, 220, 225, 232, 238, 242, 246, 249, 261, 264, 275, 289]\n# 读取CSV文件\ndf = pd.read_csv('/kaggle/input/d-n-transformer/test.csv')\n\n# 根据给定的行号提取filename列的值\nselected_filenames = df.loc[rows, 'filename']\n\n# 打印结果\nprint(selected_filenames)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T08:02:21.913486Z","iopub.execute_input":"2024-03-29T08:02:21.914445Z","iopub.status.idle":"2024-03-29T08:02:21.942261Z","shell.execute_reply.started":"2024-03-29T08:02:21.914409Z","shell.execute_reply":"2024-03-29T08:02:21.941286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\n\n# 定义CSV文件的路径\ncsv_file_path = '/kaggle/input/d-n-transformer/test.csv'\n# 使用Pandas读取CSV文件\ntry:\n    df = pd.read_csv(csv_file_path)\n    test_df = df\n    print(\"CSV文件成功加载到DataFrame中。\")\nexcept FileNotFoundError:\n    print(f\"未找到文件：{csv_file_path}。请检查文件路径是否正确。\")\nexcept Exception as e:\n    print(f\"读取CSV文件时出错：{e}\")\n\n# 原始图像文件夹路径\nsource_folder = '/kaggle/input/transformer-gaus-images/normalized_gaus_test/normalized_gaus_test'\n\n# 新的测试集图像文件夹路径\ntest_images_folder = '/kaggle/working/all_normalized_double_test_images'\n\n# 创建新的文件夹（如果不存在）\nos.makedirs(test_images_folder, exist_ok=True)\n\n# 从DataFrame中提取测试集的图像文件名\ntest_filenames = test_df['filename'].tolist()\n\n# 复制测试集图像到新的测试集文件夹\nfor filename in test_filenames:\n    # 确保文件名是字符串类型，添加.npy扩展名（如果需要）\n    filename_str = str(filename) + '.npy'  # 假设你需要添加.npy扩展名\n    source_path = os.path.join(source_folder, filename_str)\n    destination_path = os.path.join(test_images_folder, filename_str)\n    # 检查源文件是否存在，再复制\n    if os.path.exists(source_path):\n        shutil.copy(source_path, destination_path)\n    else:\n        print(f\"文件不存在：{source_path}\")\n\nprint(\"图像已复制到相应的测试集文件夹。\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T08:09:05.671104Z","iopub.execute_input":"2024-03-29T08:09:05.671958Z","iopub.status.idle":"2024-03-29T08:09:18.258628Z","shell.execute_reply.started":"2024-03-29T08:09:05.671924Z","shell.execute_reply":"2024-03-29T08:09:18.257591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# 基于之前的预测结果计算混淆矩阵\ncm = confusion_matrix(all_labels, all_preds)\n\n# 绘制混淆矩阵的热力图\nplt.figure(figsize=(12, 10))  # 根据需要调整图像的大小\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", xticklabels=range(len(np.unique(all_labels))), yticklabels=range(len(np.unique(all_labels))))\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T08:02:35.023628Z","iopub.execute_input":"2024-03-29T08:02:35.024359Z","iopub.status.idle":"2024-03-29T08:02:35.359419Z","shell.execute_reply.started":"2024-03-29T08:02:35.024329Z","shell.execute_reply":"2024-03-29T08:02:35.358327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 保存模型权重\nmodel_path = '/kaggle/working/trained_model.pth'  # 指定模型保存路径\ntorch.save(model.state_dict(), model_path)  # 保存模型权重","metadata":{"execution":{"iopub.status.busy":"2024-03-29T07:39:27.493004Z","iopub.execute_input":"2024-03-29T07:39:27.493933Z","iopub.status.idle":"2024-03-29T07:39:27.665046Z","shell.execute_reply.started":"2024-03-29T07:39:27.493895Z","shell.execute_reply":"2024-03-29T07:39:27.663912Z"},"trusted":true},"execution_count":null,"outputs":[]}]}