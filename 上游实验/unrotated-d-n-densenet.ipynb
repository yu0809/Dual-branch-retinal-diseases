{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom torchvision import models\nfrom sklearn.preprocessing import LabelEncoder\nimport os\n\n# 设置随机种子以确保可重复性\ndef set_seed(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# 数据集类\nclass NPYDataset(Dataset):\n    def __init__(self, csv_file, root_dir):\n        try:\n            self.annotations = pd.read_csv(csv_file, encoding='utf-8')\n        except UnicodeDecodeError:\n            self.annotations = pd.read_csv(csv_file, encoding='gbk')\n        self.root_dir = root_dir\n        self.le = LabelEncoder()\n        self.annotations['labels'] = self.annotations['labels'].apply(lambda x: x.strip(\"[]'\"))\n        self.annotations['labels'] = self.le.fit_transform(self.annotations['labels'])\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_name = os.path.join(self.root_dir, str(self.annotations.iloc[index, -1]) + '.npy')\n        image = np.load(img_name)\n        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n        label = self.annotations.iloc[index, 2]\n        return image, label\n\n# 模型定义\nclass DenseNet2D(nn.Module):\n    def __init__(self, num_classes):\n        super(DenseNet2D, self).__init__()\n        # 使用预训练的DenseNet模型\n        self.densenet = models.densenet121(pretrained=True)\n        self.dropout = nn.Dropout(0.5)  # 添加Dropout层\n        \n        # DenseNet的分类器部分是一个名为classifier的线性层\n        # 我们需要用新的线性层替换它，以匹配我们的类别数目\n        self.densenet.classifier = nn.Linear(self.densenet.classifier.in_features, num_classes)\n        \n        # 由于我们已经在上面的行中将原始的分类器替换掉了，\n        # 所以这里不需要再替换fc层为Identity\n\n    def forward(self, x):\n        # 通过DenseNet模型\n        x = self.densenet(x)\n        # Dropout层现在不是必需的，因为我们在最后一层之前已经包含了dropout\n        # x = self.dropout(x)\n        # 由于我们已经将分类器层替换为自定义的线性层，以下步骤也不再需要\n        # x = self.fc(x)\n        return x\n\n# 训练和评估参数\nnum_epochs = 10\nbatch_size = 16\nlearning_rate = 0.0005\n\n# 设备配置\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 数据加载\ntrain_dataset = NPYDataset(csv_file='/kaggle/input/d-n-classification/train.csv', root_dir='/kaggle/input/d-n-classification/normalized_train_images/normalized_train_images')\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n\nvalidation_dataset = NPYDataset(csv_file='/kaggle/input/d-n-classification/validation.csv', root_dir='/kaggle/input/d-n-classification/normalized_validation_images/normalized_validation_images')\nvalidation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n\ntest_dataset = NPYDataset(csv_file='/kaggle/input/d-n-classification/test.csv', root_dir='/kaggle/input/d-n-classification/normalized_test_images/normalized_test_images')\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n# 模型初始化\nnum_classes = len(np.unique(train_dataset.annotations['labels']))\n\n# 创建一个权重数组\n# 这里假设类别标签已经编码为0, 1\nweights = torch.tensor([1.0, 1.0], dtype=torch.float32).to(device)\n\n# 使用加权损失函数\ncriterion = nn.CrossEntropyLoss(weight=weights)\n\nmodel = DenseNet2D(num_classes=num_classes).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)  # 增加权重衰减\n\n# 学习率调度器\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n# 训练模型的代码...\n# 请根据您的具体需求添加训练循环和验证/测试循环","metadata":{"execution":{"iopub.status.busy":"2024-03-20T09:47:24.982515Z","iopub.execute_input":"2024-03-20T09:47:24.982903Z","iopub.status.idle":"2024-03-20T09:47:33.731615Z","shell.execute_reply.started":"2024-03-20T09:47:24.982875Z","shell.execute_reply":"2024-03-20T09:47:33.730623Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 130MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# 确保模型在GPU上\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# 确保模型处于训练模式\nmodel.train()\n\n# 可能需要调整学习率\n#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)  # 示例学习率\n\nfor epoch in range(0, 30):  # 继续训练过程\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).long()\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # 每个epoch结束后打印损失\n    print(f'Epoch [{epoch+1}/{30}], Loss: {loss.item():.4f}')\n    \n    # 每个epoch结束后在训练集上评估模型\n    model.eval()  # 切换到评估模式\n    with torch.no_grad():\n        train_preds = []\n        train_labels = []\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            train_preds.extend(predicted.view(-1).cpu().numpy())\n            train_labels.extend(labels.view(-1).cpu().numpy())\n        train_accuracy = 100 * np.sum(np.array(train_preds) == np.array(train_labels)) / len(train_labels)\n        print(f'Train Accuracy: {train_accuracy:.2f} %')\n\n    # 每个epoch结束后在验证集上评估模型\n    with torch.no_grad():\n        val_preds = []\n        val_labels = []\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            val_preds.extend(predicted.view(-1).cpu().numpy())\n            val_labels.extend(labels.view(-1).cpu().numpy())\n        val_accuracy = 100 * np.sum(np.array(val_preds) == np.array(val_labels)) / len(val_labels)\n        print(f'Validation Accuracy: {val_accuracy:.2f} %')\n    \n    # 每个epoch结束后在测试集上评估模型\n    with torch.no_grad():\n        test_preds = []\n        test_labels = []\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            test_preds.extend(predicted.view(-1).cpu().numpy())\n            test_labels.extend(labels.view(-1).cpu().numpy())\n    \n        test_accuracy = 100 * np.sum(np.array(test_preds) == np.array(test_labels)) / len(test_labels)\n        print(f'Test Accuracy: {test_accuracy:.2f} %')\n\n        # 计算精确率、召回率和F1分数\n        precision = precision_score(test_labels, test_preds, average='weighted')\n        recall = recall_score(test_labels, test_preds, average='weighted')\n        f1 = f1_score(test_labels, test_preds, average='weighted')\n    \n        print(f'Precision: {precision:.4f}')\n        print(f'Recall: {recall:.4f}')\n        print(f'F1 Score: {f1:.4f}')\n    \n    model.train()  # 切换回训练模式","metadata":{"execution":{"iopub.status.busy":"2024-03-20T09:47:33.733233Z","iopub.execute_input":"2024-03-20T09:47:33.733530Z","iopub.status.idle":"2024-03-20T10:03:22.675153Z","shell.execute_reply.started":"2024-03-20T09:47:33.733506Z","shell.execute_reply":"2024-03-20T10:03:22.674125Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch [1/30], Loss: 0.6285\nTrain Accuracy: 53.14 %\nValidation Accuracy: 54.67 %\nTest Accuracy: 54.00 %\nPrecision: 0.7589\nRecall: 0.5400\nF1 Score: 0.4109\nEpoch [2/30], Loss: 0.5363\nTrain Accuracy: 72.43 %\nValidation Accuracy: 66.67 %\nTest Accuracy: 68.67 %\nPrecision: 0.7542\nRecall: 0.6867\nF1 Score: 0.6626\nEpoch [3/30], Loss: 0.5165\nTrain Accuracy: 79.29 %\nValidation Accuracy: 70.00 %\nTest Accuracy: 75.33 %\nPrecision: 0.7805\nRecall: 0.7533\nF1 Score: 0.7479\nEpoch [4/30], Loss: 0.6072\nTrain Accuracy: 93.14 %\nValidation Accuracy: 79.33 %\nTest Accuracy: 78.67 %\nPrecision: 0.7876\nRecall: 0.7867\nF1 Score: 0.7866\nEpoch [5/30], Loss: 0.8036\nTrain Accuracy: 76.14 %\nValidation Accuracy: 69.33 %\nTest Accuracy: 70.67 %\nPrecision: 0.7615\nRecall: 0.7067\nF1 Score: 0.6918\nEpoch [6/30], Loss: 0.2684\nTrain Accuracy: 91.57 %\nValidation Accuracy: 72.67 %\nTest Accuracy: 80.67 %\nPrecision: 0.8333\nRecall: 0.8067\nF1 Score: 0.8032\nEpoch [7/30], Loss: 0.3546\nTrain Accuracy: 93.14 %\nValidation Accuracy: 72.67 %\nTest Accuracy: 80.00 %\nPrecision: 0.8189\nRecall: 0.8000\nF1 Score: 0.7974\nEpoch [8/30], Loss: 0.1374\nTrain Accuracy: 94.86 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 78.67 %\nPrecision: 0.8080\nRecall: 0.7867\nF1 Score: 0.7824\nEpoch [9/30], Loss: 0.0657\nTrain Accuracy: 96.57 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 84.00 %\nPrecision: 0.8526\nRecall: 0.8400\nF1 Score: 0.8388\nEpoch [10/30], Loss: 0.0811\nTrain Accuracy: 97.00 %\nValidation Accuracy: 78.67 %\nTest Accuracy: 78.00 %\nPrecision: 0.7882\nRecall: 0.7800\nF1 Score: 0.7781\nEpoch [11/30], Loss: 0.0236\nTrain Accuracy: 97.43 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 76.67 %\nPrecision: 0.7693\nRecall: 0.7667\nF1 Score: 0.7663\nEpoch [12/30], Loss: 0.0870\nTrain Accuracy: 93.14 %\nValidation Accuracy: 68.67 %\nTest Accuracy: 76.67 %\nPrecision: 0.8072\nRecall: 0.7667\nF1 Score: 0.7595\nEpoch [13/30], Loss: 0.0737\nTrain Accuracy: 95.71 %\nValidation Accuracy: 80.00 %\nTest Accuracy: 78.67 %\nPrecision: 0.8036\nRecall: 0.7867\nF1 Score: 0.7832\nEpoch [14/30], Loss: 0.1348\nTrain Accuracy: 90.29 %\nValidation Accuracy: 73.33 %\nTest Accuracy: 76.00 %\nPrecision: 0.7853\nRecall: 0.7600\nF1 Score: 0.7552\nEpoch [15/30], Loss: 0.1656\nTrain Accuracy: 97.71 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 78.67 %\nPrecision: 0.7868\nRecall: 0.7867\nF1 Score: 0.7866\nEpoch [16/30], Loss: 0.1314\nTrain Accuracy: 97.29 %\nValidation Accuracy: 82.67 %\nTest Accuracy: 82.00 %\nPrecision: 0.8329\nRecall: 0.8200\nF1 Score: 0.8179\nEpoch [17/30], Loss: 0.0537\nTrain Accuracy: 98.29 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 78.67 %\nPrecision: 0.8143\nRecall: 0.7867\nF1 Score: 0.7824\nEpoch [18/30], Loss: 0.0054\nTrain Accuracy: 99.86 %\nValidation Accuracy: 79.33 %\nTest Accuracy: 79.33 %\nPrecision: 0.7948\nRecall: 0.7933\nF1 Score: 0.7932\nEpoch [19/30], Loss: 0.8184\nTrain Accuracy: 99.86 %\nValidation Accuracy: 74.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8270\nRecall: 0.8267\nF1 Score: 0.8267\nEpoch [20/30], Loss: 0.1659\nTrain Accuracy: 82.00 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 67.33 %\nPrecision: 0.7022\nRecall: 0.6733\nF1 Score: 0.6597\nEpoch [21/30], Loss: 0.1614\nTrain Accuracy: 91.57 %\nValidation Accuracy: 71.33 %\nTest Accuracy: 77.33 %\nPrecision: 0.8115\nRecall: 0.7733\nF1 Score: 0.7669\nEpoch [22/30], Loss: 0.0870\nTrain Accuracy: 98.57 %\nValidation Accuracy: 78.67 %\nTest Accuracy: 84.00 %\nPrecision: 0.8402\nRecall: 0.8400\nF1 Score: 0.8399\nEpoch [23/30], Loss: 0.0110\nTrain Accuracy: 99.57 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 81.33 %\nPrecision: 0.8287\nRecall: 0.8133\nF1 Score: 0.8115\nEpoch [24/30], Loss: 0.0028\nTrain Accuracy: 100.00 %\nValidation Accuracy: 80.67 %\nTest Accuracy: 86.00 %\nPrecision: 0.8600\nRecall: 0.8600\nF1 Score: 0.8600\nEpoch [25/30], Loss: 0.0016\nTrain Accuracy: 100.00 %\nValidation Accuracy: 78.00 %\nTest Accuracy: 86.67 %\nPrecision: 0.8692\nRecall: 0.8667\nF1 Score: 0.8665\nEpoch [26/30], Loss: 0.0006\nTrain Accuracy: 100.00 %\nValidation Accuracy: 78.00 %\nTest Accuracy: 88.00 %\nPrecision: 0.8812\nRecall: 0.8800\nF1 Score: 0.8800\nEpoch [27/30], Loss: 1.0239\nTrain Accuracy: 100.00 %\nValidation Accuracy: 79.33 %\nTest Accuracy: 86.00 %\nPrecision: 0.8600\nRecall: 0.8600\nF1 Score: 0.8600\nEpoch [28/30], Loss: 0.0114\nTrain Accuracy: 99.14 %\nValidation Accuracy: 80.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8290\nRecall: 0.8267\nF1 Score: 0.8265\nEpoch [29/30], Loss: 0.0139\nTrain Accuracy: 98.43 %\nValidation Accuracy: 74.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8307\nRecall: 0.8267\nF1 Score: 0.8263\nEpoch [30/30], Loss: 0.1573\nTrain Accuracy: 100.00 %\nValidation Accuracy: 79.33 %\nTest Accuracy: 82.00 %\nPrecision: 0.8226\nRecall: 0.8200\nF1 Score: 0.8195\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# 确保模型在GPU上\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# 确保模型处于训练模式\nmodel.train()\n\n# 可能需要调整学习率\n#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)  # 示例学习率\n\nfor epoch in range(30, 50):  # 继续训练过程\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).long()\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # 每个epoch结束后打印损失\n    print(f'Epoch [{epoch+1}/{50}], Loss: {loss.item():.4f}')\n    \n    # 每个epoch结束后在训练集上评估模型\n    model.eval()  # 切换到评估模式\n    with torch.no_grad():\n        train_preds = []\n        train_labels = []\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            train_preds.extend(predicted.view(-1).cpu().numpy())\n            train_labels.extend(labels.view(-1).cpu().numpy())\n        train_accuracy = 100 * np.sum(np.array(train_preds) == np.array(train_labels)) / len(train_labels)\n        print(f'Train Accuracy: {train_accuracy:.2f} %')\n\n    # 每个epoch结束后在验证集上评估模型\n    with torch.no_grad():\n        val_preds = []\n        val_labels = []\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            val_preds.extend(predicted.view(-1).cpu().numpy())\n            val_labels.extend(labels.view(-1).cpu().numpy())\n        val_accuracy = 100 * np.sum(np.array(val_preds) == np.array(val_labels)) / len(val_labels)\n        print(f'Validation Accuracy: {val_accuracy:.2f} %')\n    \n    # 每个epoch结束后在测试集上评估模型\n    with torch.no_grad():\n        test_preds = []\n        test_labels = []\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            test_preds.extend(predicted.view(-1).cpu().numpy())\n            test_labels.extend(labels.view(-1).cpu().numpy())\n    \n        test_accuracy = 100 * np.sum(np.array(test_preds) == np.array(test_labels)) / len(test_labels)\n        print(f'Test Accuracy: {test_accuracy:.2f} %')\n\n        # 计算精确率、召回率和F1分数\n        precision = precision_score(test_labels, test_preds, average='weighted')\n        recall = recall_score(test_labels, test_preds, average='weighted')\n        f1 = f1_score(test_labels, test_preds, average='weighted')\n    \n        print(f'Precision: {precision:.4f}')\n        print(f'Recall: {recall:.4f}')\n        print(f'F1 Score: {f1:.4f}')\n    \n    model.train()  # 切换回训练模式","metadata":{"execution":{"iopub.status.busy":"2024-03-20T10:03:59.326049Z","iopub.execute_input":"2024-03-20T10:03:59.326961Z","iopub.status.idle":"2024-03-20T10:11:21.204409Z","shell.execute_reply.started":"2024-03-20T10:03:59.326928Z","shell.execute_reply":"2024-03-20T10:11:21.203130Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Epoch [31/50], Loss: 0.0045\nTrain Accuracy: 99.57 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 80.67 %\nPrecision: 0.8166\nRecall: 0.8067\nF1 Score: 0.8054\nEpoch [32/50], Loss: 0.0040\nTrain Accuracy: 99.29 %\nValidation Accuracy: 76.67 %\nTest Accuracy: 78.00 %\nPrecision: 0.7866\nRecall: 0.7800\nF1 Score: 0.7790\nEpoch [33/50], Loss: 0.0026\nTrain Accuracy: 100.00 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 86.00 %\nPrecision: 0.8607\nRecall: 0.8600\nF1 Score: 0.8600\nEpoch [34/50], Loss: 0.0021\nTrain Accuracy: 100.00 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8270\nRecall: 0.8267\nF1 Score: 0.8267\nEpoch [35/50], Loss: 0.0004\nTrain Accuracy: 100.00 %\nValidation Accuracy: 74.00 %\nTest Accuracy: 84.00 %\nPrecision: 0.8402\nRecall: 0.8400\nF1 Score: 0.8399\nEpoch [36/50], Loss: 0.0033\nTrain Accuracy: 100.00 %\nValidation Accuracy: 74.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8267\nRecall: 0.8267\nF1 Score: 0.8267\nEpoch [37/50], Loss: 0.0077\nTrain Accuracy: 100.00 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 81.33 %\nPrecision: 0.8172\nRecall: 0.8133\nF1 Score: 0.8129\nEpoch [38/50], Loss: 0.0050\nTrain Accuracy: 100.00 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 83.33 %\nPrecision: 0.8338\nRecall: 0.8333\nF1 Score: 0.8332\nEpoch [39/50], Loss: 0.0009\nTrain Accuracy: 100.00 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8270\nRecall: 0.8267\nF1 Score: 0.8267\nEpoch [40/50], Loss: 0.0008\nTrain Accuracy: 100.00 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8270\nRecall: 0.8267\nF1 Score: 0.8267\nEpoch [41/50], Loss: 0.0001\nTrain Accuracy: 100.00 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 83.33 %\nPrecision: 0.8334\nRecall: 0.8333\nF1 Score: 0.8333\nEpoch [42/50], Loss: 0.0001\nTrain Accuracy: 100.00 %\nValidation Accuracy: 74.67 %\nTest Accuracy: 84.67 %\nPrecision: 0.8467\nRecall: 0.8467\nF1 Score: 0.8466\nEpoch [43/50], Loss: 0.0872\nTrain Accuracy: 51.00 %\nValidation Accuracy: 52.00 %\nTest Accuracy: 50.67 %\nPrecision: 0.2567\nRecall: 0.5067\nF1 Score: 0.3408\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch [44/50], Loss: 0.1361\nTrain Accuracy: 85.14 %\nValidation Accuracy: 69.33 %\nTest Accuracy: 74.00 %\nPrecision: 0.7710\nRecall: 0.7400\nF1 Score: 0.7332\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# 继续训练过程\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 17\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     18\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}