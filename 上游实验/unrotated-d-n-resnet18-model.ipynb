{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7856224,"sourceType":"datasetVersion","datasetId":4607874}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom torchvision import models\nfrom sklearn.preprocessing import LabelEncoder\nimport os\n\n# 设置随机种子以确保可重复性\ndef set_seed(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# 数据集类\nclass NPYDataset(Dataset):\n    def __init__(self, csv_file, root_dir):\n        try:\n            self.annotations = pd.read_csv(csv_file, encoding='utf-8')\n        except UnicodeDecodeError:\n            self.annotations = pd.read_csv(csv_file, encoding='gbk')\n        self.root_dir = root_dir\n        self.le = LabelEncoder()\n        self.annotations['labels'] = self.annotations['labels'].apply(lambda x: x.strip(\"[]'\"))\n        self.annotations['labels'] = self.le.fit_transform(self.annotations['labels'])\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_name = os.path.join(self.root_dir, str(self.annotations.iloc[index, -1]) + '.npy')\n        image = np.load(img_name)\n        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n        label = self.annotations.iloc[index, 2]\n        return image, label\n\n# 模型定义\nclass ResNet2D(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNet2D, self).__init__()\n        self.resnet = models.resnet18(pretrained=True)\n        self.dropout = nn.Dropout(0.5)  # 添加Dropout层\n        self.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n        self.resnet.fc = nn.Identity()  # 将原始fc层替换为Identity\n\n    def forward(self, x):\n        x = self.resnet(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x\n\n# 训练和评估参数\nnum_epochs = 10\nbatch_size = 32\nlearning_rate = 0.0005\n\n# 设备配置\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 数据加载\ntrain_dataset = NPYDataset(csv_file='/kaggle/input/d-n-classification/train.csv', root_dir='/kaggle/input/d-n-classification/normalized_train_images/normalized_train_images')\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n\nvalidation_dataset = NPYDataset(csv_file='/kaggle/input/d-n-classification/validation.csv', root_dir='/kaggle/input/d-n-classification/normalized_validation_images/normalized_validation_images')\nvalidation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n\ntest_dataset = NPYDataset(csv_file='/kaggle/input/d-n-classification/test.csv', root_dir='/kaggle/input/d-n-classification/normalized_test_images/normalized_test_images')\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n# 模型初始化\nnum_classes = len(np.unique(train_dataset.annotations['labels']))\n\n# 创建一个权重数组\n# 这里假设类别标签已经编码为0, 1\nweights = torch.tensor([1.0, 1.0], dtype=torch.float32).to(device)\n\n# 使用加权损失函数\ncriterion = nn.CrossEntropyLoss(weight=weights)\n\nmodel = ResNet2D(num_classes=num_classes).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)  # 增加权重衰减\n\n# 学习率调度器\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n# 训练模型的代码...\n# 请根据您的具体需求添加训练循环和验证/测试循环","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-20T10:14:35.727862Z","iopub.execute_input":"2024-03-20T10:14:35.728219Z","iopub.status.idle":"2024-03-20T10:14:44.201316Z","shell.execute_reply.started":"2024-03-20T10:14:35.728189Z","shell.execute_reply":"2024-03-20T10:14:44.200318Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 163MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# 确保模型在GPU上\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# 确保模型处于训练模式\nmodel.train()\n\n# 可能需要调整学习率\n#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)  # 示例学习率\n\nfor epoch in range(0, 50):  # 继续训练过程\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).long()\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # 每个epoch结束后打印损失\n    print(f'Epoch [{epoch+1}/{50}], Loss: {loss.item():.4f}')\n    \n    # 每个epoch结束后在训练集上评估模型\n    model.eval()  # 切换到评估模式\n    with torch.no_grad():\n        train_preds = []\n        train_labels = []\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            train_preds.extend(predicted.view(-1).cpu().numpy())\n            train_labels.extend(labels.view(-1).cpu().numpy())\n        train_accuracy = 100 * np.sum(np.array(train_preds) == np.array(train_labels)) / len(train_labels)\n        print(f'Train Accuracy: {train_accuracy:.2f} %')\n\n    # 每个epoch结束后在验证集上评估模型\n    with torch.no_grad():\n        val_preds = []\n        val_labels = []\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            val_preds.extend(predicted.view(-1).cpu().numpy())\n            val_labels.extend(labels.view(-1).cpu().numpy())\n        val_accuracy = 100 * np.sum(np.array(val_preds) == np.array(val_labels)) / len(val_labels)\n        print(f'Validation Accuracy: {val_accuracy:.2f} %')\n    \n    # 每个epoch结束后在测试集上评估模型\n    with torch.no_grad():\n        test_preds = []\n        test_labels = []\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            test_preds.extend(predicted.view(-1).cpu().numpy())\n            test_labels.extend(labels.view(-1).cpu().numpy())\n    \n        test_accuracy = 100 * np.sum(np.array(test_preds) == np.array(test_labels)) / len(test_labels)\n        print(f'Test Accuracy: {test_accuracy:.2f} %')\n\n        # 计算精确率、召回率和F1分数\n        precision = precision_score(test_labels, test_preds, average='weighted')\n        recall = recall_score(test_labels, test_preds, average='weighted')\n        f1 = f1_score(test_labels, test_preds, average='weighted')\n    \n        print(f'Precision: {precision:.4f}')\n        print(f'Recall: {recall:.4f}')\n        print(f'F1 Score: {f1:.4f}')\n    \n    model.train()  # 切换回训练模式","metadata":{"execution":{"iopub.status.busy":"2024-03-20T10:14:47.809623Z","iopub.execute_input":"2024-03-20T10:14:47.809995Z","iopub.status.idle":"2024-03-20T10:27:35.239080Z","shell.execute_reply.started":"2024-03-20T10:14:47.809967Z","shell.execute_reply":"2024-03-20T10:27:35.237969Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch [1/50], Loss: 0.5250\nTrain Accuracy: 55.86 %\nValidation Accuracy: 56.67 %\nTest Accuracy: 56.67 %\nPrecision: 0.6911\nRecall: 0.5667\nF1 Score: 0.4768\nEpoch [2/50], Loss: 0.2869\nTrain Accuracy: 74.86 %\nValidation Accuracy: 72.00 %\nTest Accuracy: 70.00 %\nPrecision: 0.7465\nRecall: 0.7000\nF1 Score: 0.6837\nEpoch [3/50], Loss: 0.2324\nTrain Accuracy: 88.29 %\nValidation Accuracy: 70.67 %\nTest Accuracy: 78.00 %\nPrecision: 0.7822\nRecall: 0.7800\nF1 Score: 0.7794\nEpoch [4/50], Loss: 0.2048\nTrain Accuracy: 86.43 %\nValidation Accuracy: 71.33 %\nTest Accuracy: 75.33 %\nPrecision: 0.7988\nRecall: 0.7533\nF1 Score: 0.7445\nEpoch [5/50], Loss: 0.2661\nTrain Accuracy: 97.86 %\nValidation Accuracy: 79.33 %\nTest Accuracy: 80.00 %\nPrecision: 0.8037\nRecall: 0.8000\nF1 Score: 0.7996\nEpoch [6/50], Loss: 0.2365\nTrain Accuracy: 96.29 %\nValidation Accuracy: 76.67 %\nTest Accuracy: 79.33 %\nPrecision: 0.8020\nRecall: 0.7933\nF1 Score: 0.7915\nEpoch [7/50], Loss: 0.1530\nTrain Accuracy: 98.14 %\nValidation Accuracy: 78.00 %\nTest Accuracy: 82.00 %\nPrecision: 0.8201\nRecall: 0.8200\nF1 Score: 0.8200\nEpoch [8/50], Loss: 0.1990\nTrain Accuracy: 96.71 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 79.33 %\nPrecision: 0.7957\nRecall: 0.7933\nF1 Score: 0.7928\nEpoch [9/50], Loss: 0.0899\nTrain Accuracy: 96.57 %\nValidation Accuracy: 70.00 %\nTest Accuracy: 84.67 %\nPrecision: 0.8615\nRecall: 0.8467\nF1 Score: 0.8453\nEpoch [10/50], Loss: 0.1991\nTrain Accuracy: 88.29 %\nValidation Accuracy: 71.33 %\nTest Accuracy: 82.00 %\nPrecision: 0.8605\nRecall: 0.8200\nF1 Score: 0.8153\nEpoch [11/50], Loss: 0.0852\nTrain Accuracy: 98.57 %\nValidation Accuracy: 76.67 %\nTest Accuracy: 79.33 %\nPrecision: 0.7973\nRecall: 0.7933\nF1 Score: 0.7924\nEpoch [12/50], Loss: 0.0369\nTrain Accuracy: 93.14 %\nValidation Accuracy: 70.67 %\nTest Accuracy: 70.00 %\nPrecision: 0.7866\nRecall: 0.7000\nF1 Score: 0.6771\nEpoch [13/50], Loss: 0.0063\nTrain Accuracy: 100.00 %\nValidation Accuracy: 80.67 %\nTest Accuracy: 82.67 %\nPrecision: 0.8302\nRecall: 0.8267\nF1 Score: 0.8260\nEpoch [14/50], Loss: 0.0213\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.67 %\nTest Accuracy: 82.00 %\nPrecision: 0.8201\nRecall: 0.8200\nF1 Score: 0.8200\nEpoch [15/50], Loss: 0.0134\nTrain Accuracy: 100.00 %\nValidation Accuracy: 78.67 %\nTest Accuracy: 84.00 %\nPrecision: 0.8566\nRecall: 0.8400\nF1 Score: 0.8384\nEpoch [16/50], Loss: 0.0008\nTrain Accuracy: 100.00 %\nValidation Accuracy: 81.33 %\nTest Accuracy: 86.00 %\nPrecision: 0.8617\nRecall: 0.8600\nF1 Score: 0.8599\nEpoch [17/50], Loss: 0.0003\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.00 %\nTest Accuracy: 84.67 %\nPrecision: 0.8473\nRecall: 0.8467\nF1 Score: 0.8466\nEpoch [18/50], Loss: 0.0023\nTrain Accuracy: 100.00 %\nValidation Accuracy: 81.33 %\nTest Accuracy: 81.33 %\nPrecision: 0.8219\nRecall: 0.8133\nF1 Score: 0.8123\nEpoch [19/50], Loss: 0.0009\nTrain Accuracy: 100.00 %\nValidation Accuracy: 84.00 %\nTest Accuracy: 85.33 %\nPrecision: 0.8576\nRecall: 0.8533\nF1 Score: 0.8530\nEpoch [20/50], Loss: 0.0003\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.67 %\nTest Accuracy: 86.00 %\nPrecision: 0.8655\nRecall: 0.8600\nF1 Score: 0.8596\nEpoch [21/50], Loss: 0.0060\nTrain Accuracy: 100.00 %\nValidation Accuracy: 84.00 %\nTest Accuracy: 85.33 %\nPrecision: 0.8600\nRecall: 0.8533\nF1 Score: 0.8528\nEpoch [22/50], Loss: 0.0009\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.67 %\nTest Accuracy: 87.33 %\nPrecision: 0.8751\nRecall: 0.8733\nF1 Score: 0.8732\nEpoch [23/50], Loss: 0.0002\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.67 %\nTest Accuracy: 88.00 %\nPrecision: 0.8812\nRecall: 0.8800\nF1 Score: 0.8800\nEpoch [24/50], Loss: 0.0033\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.00 %\nTest Accuracy: 89.33 %\nPrecision: 0.8937\nRecall: 0.8933\nF1 Score: 0.8933\nEpoch [25/50], Loss: 0.0018\nTrain Accuracy: 100.00 %\nValidation Accuracy: 84.67 %\nTest Accuracy: 86.00 %\nPrecision: 0.8633\nRecall: 0.8600\nF1 Score: 0.8598\nEpoch [26/50], Loss: 0.0001\nTrain Accuracy: 100.00 %\nValidation Accuracy: 85.33 %\nTest Accuracy: 86.67 %\nPrecision: 0.8692\nRecall: 0.8667\nF1 Score: 0.8665\nEpoch [27/50], Loss: 0.0009\nTrain Accuracy: 100.00 %\nValidation Accuracy: 76.00 %\nTest Accuracy: 86.00 %\nPrecision: 0.8753\nRecall: 0.8600\nF1 Score: 0.8588\nEpoch [28/50], Loss: 0.0008\nTrain Accuracy: 100.00 %\nValidation Accuracy: 80.00 %\nTest Accuracy: 82.67 %\nPrecision: 0.8286\nRecall: 0.8267\nF1 Score: 0.8263\nEpoch [29/50], Loss: 0.0022\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.00 %\nTest Accuracy: 82.00 %\nPrecision: 0.8230\nRecall: 0.8200\nF1 Score: 0.8197\nEpoch [30/50], Loss: 0.0013\nTrain Accuracy: 100.00 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 82.00 %\nPrecision: 0.8274\nRecall: 0.8200\nF1 Score: 0.8192\nEpoch [31/50], Loss: 0.0007\nTrain Accuracy: 100.00 %\nValidation Accuracy: 80.67 %\nTest Accuracy: 84.00 %\nPrecision: 0.8411\nRecall: 0.8400\nF1 Score: 0.8399\nEpoch [32/50], Loss: 0.0001\nTrain Accuracy: 100.00 %\nValidation Accuracy: 80.67 %\nTest Accuracy: 82.00 %\nPrecision: 0.8201\nRecall: 0.8200\nF1 Score: 0.8200\nEpoch [33/50], Loss: 0.0007\nTrain Accuracy: 100.00 %\nValidation Accuracy: 81.33 %\nTest Accuracy: 82.67 %\nPrecision: 0.8270\nRecall: 0.8267\nF1 Score: 0.8267\nEpoch [34/50], Loss: 0.0006\nTrain Accuracy: 100.00 %\nValidation Accuracy: 81.33 %\nTest Accuracy: 82.67 %\nPrecision: 0.8270\nRecall: 0.8267\nF1 Score: 0.8267\nEpoch [35/50], Loss: 0.0003\nTrain Accuracy: 100.00 %\nValidation Accuracy: 82.67 %\nTest Accuracy: 83.33 %\nPrecision: 0.8350\nRecall: 0.8333\nF1 Score: 0.8332\nEpoch [36/50], Loss: 0.0000\nTrain Accuracy: 100.00 %\nValidation Accuracy: 80.67 %\nTest Accuracy: 84.00 %\nPrecision: 0.8441\nRecall: 0.8400\nF1 Score: 0.8397\nEpoch [37/50], Loss: 0.0019\nTrain Accuracy: 99.43 %\nValidation Accuracy: 82.00 %\nTest Accuracy: 80.00 %\nPrecision: 0.8010\nRecall: 0.8000\nF1 Score: 0.7999\nEpoch [38/50], Loss: 0.0430\nTrain Accuracy: 98.00 %\nValidation Accuracy: 76.67 %\nTest Accuracy: 78.00 %\nPrecision: 0.8098\nRecall: 0.7800\nF1 Score: 0.7752\nEpoch [39/50], Loss: 0.1741\nTrain Accuracy: 65.86 %\nValidation Accuracy: 58.00 %\nTest Accuracy: 58.00 %\nPrecision: 0.7731\nRecall: 0.5800\nF1 Score: 0.4940\nEpoch [40/50], Loss: 0.3211\nTrain Accuracy: 56.71 %\nValidation Accuracy: 50.67 %\nTest Accuracy: 56.00 %\nPrecision: 0.7254\nRecall: 0.5600\nF1 Score: 0.4664\nEpoch [41/50], Loss: 0.0974\nTrain Accuracy: 95.57 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 76.67 %\nPrecision: 0.7709\nRecall: 0.7667\nF1 Score: 0.7660\nEpoch [42/50], Loss: 0.1098\nTrain Accuracy: 99.43 %\nValidation Accuracy: 75.33 %\nTest Accuracy: 83.33 %\nPrecision: 0.8365\nRecall: 0.8333\nF1 Score: 0.8331\nEpoch [43/50], Loss: 0.0353\nTrain Accuracy: 100.00 %\nValidation Accuracy: 79.33 %\nTest Accuracy: 83.33 %\nPrecision: 0.8385\nRecall: 0.8333\nF1 Score: 0.8329\nEpoch [44/50], Loss: 0.0251\nTrain Accuracy: 99.86 %\nValidation Accuracy: 72.67 %\nTest Accuracy: 79.33 %\nPrecision: 0.8307\nRecall: 0.7933\nF1 Score: 0.7879\nEpoch [45/50], Loss: 0.0101\nTrain Accuracy: 100.00 %\nValidation Accuracy: 77.33 %\nTest Accuracy: 83.33 %\nPrecision: 0.8334\nRecall: 0.8333\nF1 Score: 0.8333\nEpoch [46/50], Loss: 0.0026\nTrain Accuracy: 100.00 %\nValidation Accuracy: 78.67 %\nTest Accuracy: 82.67 %\nPrecision: 0.8329\nRecall: 0.8267\nF1 Score: 0.8260\nEpoch [47/50], Loss: 0.0011\nTrain Accuracy: 100.00 %\nValidation Accuracy: 77.33 %\nTest Accuracy: 81.33 %\nPrecision: 0.8379\nRecall: 0.8133\nF1 Score: 0.8103\nEpoch [48/50], Loss: 0.0048\nTrain Accuracy: 100.00 %\nValidation Accuracy: 77.33 %\nTest Accuracy: 84.00 %\nPrecision: 0.8441\nRecall: 0.8400\nF1 Score: 0.8397\nEpoch [49/50], Loss: 0.0012\nTrain Accuracy: 100.00 %\nValidation Accuracy: 77.33 %\nTest Accuracy: 82.00 %\nPrecision: 0.8206\nRecall: 0.8200\nF1 Score: 0.8200\nEpoch [50/50], Loss: 0.0007\nTrain Accuracy: 100.00 %\nValidation Accuracy: 78.00 %\nTest Accuracy: 82.00 %\nPrecision: 0.8216\nRecall: 0.8200\nF1 Score: 0.8199\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch  \nimport numpy as np  \nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score  \n  \n# 假设model, test_loader, device等都已正确定义和初始化  \n  \nmodel.eval()  \nwith torch.no_grad():  \n    all_preds = []  \n    all_labels = []  \n    for images, labels in test_loader:  \n        images, labels = images.to(device), labels.to(device).long()  \n        outputs = model(images)  \n        _, predicted = torch.max(outputs.data, 1)  \n          \n        # 收集所有预测和标签  \n        all_preds.extend(predicted.view(-1).cpu().numpy())  \n        all_labels.extend(labels.view(-1).cpu().numpy())  \n  \n    # 计算准确率  \n    accuracy = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)  \n    print(f'Accuracy of the model on the test images: {accuracy:.2f} %')  \n      \n    # 计算精确率、召回率和F1分数  \n    precision = precision_score(all_labels, all_preds, average='weighted')  \n    recall = recall_score(all_labels, all_preds, average='weighted')  \n    f1 = f1_score(all_labels, all_preds, average='weighted')  \n      \n    print(f'Precision: {precision:.4f}')  \n    print(f'Recall: {recall:.4f}')  \n    print(f'F1 Score: {f1:.4f}')  \n  \n    # 计算混淆矩阵  \n    cm = confusion_matrix(all_labels, all_preds)  \n      \n    # 计算每个类别的准确率  \n    class_accuracy = cm.diagonal() / cm.sum(axis=1)  \n      \n    # 打印每个类别的准确率  \n    for i in range(len(class_accuracy)):  \n        print(f'Accuracy for class {i}: {class_accuracy[i]:.2f}')  \n  \n# 打印所有预测结果（如果需要）  \n# print('All Predictions:', all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T01:03:57.390678Z","iopub.execute_input":"2024-03-17T01:03:57.391046Z","iopub.status.idle":"2024-03-17T01:03:58.344753Z","shell.execute_reply.started":"2024-03-17T01:03:57.391012Z","shell.execute_reply":"2024-03-17T01:03:58.343826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# 基于之前的预测结果计算混淆矩阵\ncm = confusion_matrix(all_labels, all_preds)\n\n# 绘制混淆矩阵的热力图\nplt.figure(figsize=(12, 10))  # 根据需要调整图像的大小\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", xticklabels=range(len(np.unique(all_labels))), yticklabels=range(len(np.unique(all_labels))))\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T01:03:58.346856Z","iopub.execute_input":"2024-03-17T01:03:58.347282Z","iopub.status.idle":"2024-03-17T01:03:58.791878Z","shell.execute_reply.started":"2024-03-17T01:03:58.347253Z","shell.execute_reply":"2024-03-17T01:03:58.790948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 打印所有预测结果\nprint('All Predictions:', all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T01:03:58.793178Z","iopub.execute_input":"2024-03-17T01:03:58.793750Z","iopub.status.idle":"2024-03-17T01:03:58.798847Z","shell.execute_reply.started":"2024-03-17T01:03:58.793720Z","shell.execute_reply":"2024-03-17T01:03:58.797918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming `le` is your LabelEncoder instance that has been fitted to the labels\nprint(\"Label mapping:\")\nfor i, label in enumerate(train_dataset.le.classes_):\n    print(f\"{label}: {i}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T01:03:58.800116Z","iopub.execute_input":"2024-03-17T01:03:58.800419Z","iopub.status.idle":"2024-03-17T01:03:58.813346Z","shell.execute_reply.started":"2024-03-17T01:03:58.800384Z","shell.execute_reply":"2024-03-17T01:03:58.812380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 保存模型权重\nmodel_path = '/kaggle/working/trained_model.pth'  # 指定模型保存路径\ntorch.save(model.state_dict(), model_path)  # 保存模型权重","metadata":{"execution":{"iopub.status.busy":"2024-03-17T01:03:58.814477Z","iopub.execute_input":"2024-03-17T01:03:58.814738Z","iopub.status.idle":"2024-03-17T01:03:58.899382Z","shell.execute_reply.started":"2024-03-17T01:03:58.814715Z","shell.execute_reply":"2024-03-17T01:03:58.898318Z"},"trusted":true},"execution_count":null,"outputs":[]}]}