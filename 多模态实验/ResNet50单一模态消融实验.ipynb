{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 数据集类\n",
    "class NPYDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        try:\n",
    "            self.annotations = pd.read_csv(csv_file, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            self.annotations = pd.read_csv(csv_file, encoding='gbk')\n",
    "        self.root_dir = root_dir\n",
    "        self.le = LabelEncoder()\n",
    "        self.annotations['labels'] = self.annotations['labels'].apply(lambda x: x.strip(\"[]'\"))\n",
    "        self.annotations['labels'] = self.le.fit_transform(self.annotations['labels'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.root_dir, str(self.annotations.iloc[index, -1]) + '.npy')\n",
    "        image = np.load(img_name)\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = self.annotations.iloc[index, 2]\n",
    "        return image, label\n",
    "\n",
    "# 模型定义\n",
    "class ResNet2DFeatures(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNet2DFeatures, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # 移除最后一个全连接层以获取特征\n",
    "        self.features = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)  # 展平为向量\n",
    "        return x\n",
    "\n",
    "# 实例化特征提取模型\n",
    "feature_extractor = ResNet2DFeatures().to(device)\n",
    "\n",
    "# 之后的优化器、学习率调度器和训练循环可以保持不变\n",
    "\n",
    "# 训练和评估参数\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 数据加载\n",
    "train_dataset = NPYDataset(csv_file=r'C:\\Users\\HP\\Desktop\\指南者\\项目\\眼病预测\\train.csv', root_dir=r'C:\\Users\\HP\\Desktop\\指南者\\项目\\眼病预测\\normalized_gaus_train')\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = NPYDataset(csv_file=r'C:\\Users\\HP\\Desktop\\指南者\\项目\\眼病预测\\test.csv', root_dir=r'C:\\Users\\HP\\Desktop\\指南者\\项目\\眼病预测\\normalized_gaus_test')\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "validation_dataset = NPYDataset(csv_file=r'C:\\Users\\HP\\Desktop\\指南者\\项目\\眼病预测\\validation.csv', root_dir=r'C:\\Users\\HP\\Desktop\\指南者\\项目\\眼病预测\\normalized_gaus_validation')\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 模型初始化\n",
    "num_classes = len(np.unique(train_dataset.annotations['labels']))  # 这应该计算为4\n",
    "\n",
    "# 创建一个权重数组\n",
    "# 这里假设类别标签已经编码为0, 1\n",
    "weights = torch.tensor([1.0, 1.0, 1.0, 1.0], dtype=torch.float32).to(device)\n",
    "\n",
    "# 使用加权损失函数\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "model = ResNet2D(num_classes=num_classes).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)  # 增加权重衰减\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# 训练模型的代码...\n",
    "# 请根据您的具体需求添加训练循环和验证/测试循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'C:\\Users\\HP\\Desktop\\指南者\\项目\\眼病预测\\trained_model.pth'  # 指定模型保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(loader, model, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(targets.cpu().numpy())\n",
    "\n",
    "    features = np.concatenate(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels\n",
    "\n",
    "# 提取训练集、验证集和测试集的特征\n",
    "train_features, train_labels = extract_features(train_loader, feature_extractor, device)\n",
    "validation_features, validation_labels = extract_features(validation_loader, feature_extractor, device)\n",
    "test_features, test_labels = extract_features(test_loader, feature_extractor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正确的类别数，根据错误消息，应该是4\n",
    "num_classes = 4\n",
    "\n",
    "# 使用正确的类别数创建模型实例\n",
    "model = ResNet2D(num_classes=num_classes)\n",
    "\n",
    "# 现在加载模型应该不会出错，因为类别数匹配\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "# 根据你的需要调用 model.train() 或 model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 90.27 %\n",
      "Precision: 0.9146\n",
      "Recall: 0.9027\n",
      "F1 Score: 0.9039\n",
      "Accuracy for class 0: 0.98\n",
      "Accuracy for class 1: 0.77\n",
      "Accuracy for class 2: 0.94\n",
      "Accuracy for class 3: 0.92\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import numpy as np  \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score  \n",
    "  \n",
    "# 假设model, test_loader, device等都已正确定义和初始化  \n",
    "  \n",
    "model.eval()  \n",
    "with torch.no_grad():  \n",
    "    all_preds = []  \n",
    "    all_labels = []  \n",
    "    for images, labels in test_loader:  \n",
    "        images, labels = images.to(device), labels.to(device).long()  \n",
    "        outputs = model(images)  \n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "          \n",
    "        # 收集所有预测和标签  \n",
    "        all_preds.extend(predicted.view(-1).cpu().numpy())  \n",
    "        all_labels.extend(labels.view(-1).cpu().numpy())  \n",
    "  \n",
    "    # 计算准确率  \n",
    "    accuracy = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)  \n",
    "    print(f'Accuracy of the model on the test images: {accuracy:.2f} %')  \n",
    "      \n",
    "    # 计算精确率、召回率和F1分数  \n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')  \n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')  \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')  \n",
    "      \n",
    "    print(f'Precision: {precision:.4f}')  \n",
    "    print(f'Recall: {recall:.4f}')  \n",
    "    print(f'F1 Score: {f1:.4f}')  \n",
    "  \n",
    "    # 计算混淆矩阵  \n",
    "    cm = confusion_matrix(all_labels, all_preds)  \n",
    "      \n",
    "    # 计算每个类别的准确率  \n",
    "    class_accuracy = cm.diagonal() / cm.sum(axis=1)  \n",
    "      \n",
    "    # 打印每个类别的准确率  \n",
    "    for i in range(len(class_accuracy)):  \n",
    "        print(f'Accuracy for class {i}: {class_accuracy[i]:.2f}')  \n",
    "  \n",
    "# 打印所有预测结果（如果需要）  \n",
    "# print('All Predictions:', all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping:\n",
      "C: 0\n",
      "D: 1\n",
      "M: 2\n",
      "N: 3\n"
     ]
    }
   ],
   "source": [
    "# Assuming `le` is your LabelEncoder instance that has been fitted to the labels\n",
    "print(\"Label mapping:\")\n",
    "for i, label in enumerate(train_dataset.le.classes_):\n",
    "    print(f\"{label}: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 验证准确率: 0.8221\n",
      "SVM 测试准确率: 0.8389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 训练 SVM\n",
    "svm_clf = SVC(kernel='linear', C=1)\n",
    "svm_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 验证 SVM\n",
    "validation_predictions_svm = svm_clf.predict(validation_features)\n",
    "validation_accuracy_svm = accuracy_score(validation_labels, validation_predictions_svm)\n",
    "print(f'SVM 验证准确率: {validation_accuracy_svm:.4f}')\n",
    "\n",
    "# 测试 SVM\n",
    "test_predictions_svm = svm_clf.predict(test_features)\n",
    "test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm)\n",
    "print(f'SVM 测试准确率: {test_accuracy_svm:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 验证准确率: 0.8322\n",
      "MLP 测试准确率: 0.8087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 训练 MLP\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "mlp_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 验证 MLP\n",
    "validation_predictions_mlp = mlp_clf.predict(validation_features)\n",
    "validation_accuracy_mlp = accuracy_score(validation_labels, validation_predictions_mlp)\n",
    "print(f'MLP 验证准确率: {validation_accuracy_mlp:.4f}')\n",
    "\n",
    "# 测试 MLP\n",
    "test_predictions_mlp = mlp_clf.predict(test_features)\n",
    "test_accuracy_mlp = accuracy_score(test_labels, test_predictions_mlp)\n",
    "print(f'MLP 测试准确率: {test_accuracy_mlp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting xgboost\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/24/14/d9ecb9fa86727f51bfb35f1c2b0428ebc6cd5ffde24c5e2dc583d3575a6f/xgboost-1.6.2-py3-none-win_amd64.whl (125.4 MB)\n",
      "     ------------------------------------- 125.4/125.4 MB 29.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from xgboost) (1.21.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5 (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5 (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pandas 0.24.2 has a non-standard dependency specifier pytz>=2011k. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pandas or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-mlogloss:1.27678\n",
      "[1]\tvalidation-mlogloss:1.18596\n",
      "[2]\tvalidation-mlogloss:1.10482\n",
      "[3]\tvalidation-mlogloss:1.04226\n",
      "[4]\tvalidation-mlogloss:0.98213\n",
      "[5]\tvalidation-mlogloss:0.93216\n",
      "[6]\tvalidation-mlogloss:0.88883\n",
      "[7]\tvalidation-mlogloss:0.84934\n",
      "[8]\tvalidation-mlogloss:0.81408\n",
      "[9]\tvalidation-mlogloss:0.78427\n",
      "[10]\tvalidation-mlogloss:0.75769\n",
      "[11]\tvalidation-mlogloss:0.73029\n",
      "[12]\tvalidation-mlogloss:0.70713\n",
      "[13]\tvalidation-mlogloss:0.68498\n",
      "[14]\tvalidation-mlogloss:0.66780\n",
      "[15]\tvalidation-mlogloss:0.65096\n",
      "[16]\tvalidation-mlogloss:0.63548\n",
      "[17]\tvalidation-mlogloss:0.62268\n",
      "[18]\tvalidation-mlogloss:0.60741\n",
      "[19]\tvalidation-mlogloss:0.59614\n",
      "[20]\tvalidation-mlogloss:0.58516\n",
      "[21]\tvalidation-mlogloss:0.57563\n",
      "[22]\tvalidation-mlogloss:0.56677\n",
      "[23]\tvalidation-mlogloss:0.55617\n",
      "[24]\tvalidation-mlogloss:0.54900\n",
      "[25]\tvalidation-mlogloss:0.54136\n",
      "[26]\tvalidation-mlogloss:0.53531\n",
      "[27]\tvalidation-mlogloss:0.52940\n",
      "[28]\tvalidation-mlogloss:0.52493\n",
      "[29]\tvalidation-mlogloss:0.51896\n",
      "[30]\tvalidation-mlogloss:0.51194\n",
      "[31]\tvalidation-mlogloss:0.50789\n",
      "[32]\tvalidation-mlogloss:0.50391\n",
      "[33]\tvalidation-mlogloss:0.49898\n",
      "[34]\tvalidation-mlogloss:0.49437\n",
      "[35]\tvalidation-mlogloss:0.48992\n",
      "[36]\tvalidation-mlogloss:0.48554\n",
      "[37]\tvalidation-mlogloss:0.48322\n",
      "[38]\tvalidation-mlogloss:0.48133\n",
      "[39]\tvalidation-mlogloss:0.47946\n",
      "[40]\tvalidation-mlogloss:0.47884\n",
      "[41]\tvalidation-mlogloss:0.47695\n",
      "[42]\tvalidation-mlogloss:0.47559\n",
      "[43]\tvalidation-mlogloss:0.47215\n",
      "[44]\tvalidation-mlogloss:0.47073\n",
      "[45]\tvalidation-mlogloss:0.46899\n",
      "[46]\tvalidation-mlogloss:0.46770\n",
      "[47]\tvalidation-mlogloss:0.46694\n",
      "[48]\tvalidation-mlogloss:0.46541\n",
      "[49]\tvalidation-mlogloss:0.46427\n",
      "[50]\tvalidation-mlogloss:0.46405\n",
      "[51]\tvalidation-mlogloss:0.46223\n",
      "[52]\tvalidation-mlogloss:0.46159\n",
      "[53]\tvalidation-mlogloss:0.46062\n",
      "[54]\tvalidation-mlogloss:0.45974\n",
      "[55]\tvalidation-mlogloss:0.45977\n",
      "[56]\tvalidation-mlogloss:0.45902\n",
      "[57]\tvalidation-mlogloss:0.45819\n",
      "[58]\tvalidation-mlogloss:0.45560\n",
      "[59]\tvalidation-mlogloss:0.45469\n",
      "[60]\tvalidation-mlogloss:0.45156\n",
      "[61]\tvalidation-mlogloss:0.45165\n",
      "[62]\tvalidation-mlogloss:0.45264\n",
      "[63]\tvalidation-mlogloss:0.45221\n",
      "[64]\tvalidation-mlogloss:0.45172\n",
      "[65]\tvalidation-mlogloss:0.45058\n",
      "[66]\tvalidation-mlogloss:0.45069\n",
      "[67]\tvalidation-mlogloss:0.45056\n",
      "[68]\tvalidation-mlogloss:0.45023\n",
      "[69]\tvalidation-mlogloss:0.44917\n",
      "[70]\tvalidation-mlogloss:0.44919\n",
      "[71]\tvalidation-mlogloss:0.44948\n",
      "[72]\tvalidation-mlogloss:0.44890\n",
      "[73]\tvalidation-mlogloss:0.44907\n",
      "[74]\tvalidation-mlogloss:0.44920\n",
      "[75]\tvalidation-mlogloss:0.44883\n",
      "[76]\tvalidation-mlogloss:0.44820\n",
      "[77]\tvalidation-mlogloss:0.44798\n",
      "[78]\tvalidation-mlogloss:0.44881\n",
      "[79]\tvalidation-mlogloss:0.44768\n",
      "[80]\tvalidation-mlogloss:0.44738\n",
      "[81]\tvalidation-mlogloss:0.44694\n",
      "[82]\tvalidation-mlogloss:0.44722\n",
      "[83]\tvalidation-mlogloss:0.44669\n",
      "[84]\tvalidation-mlogloss:0.44662\n",
      "[85]\tvalidation-mlogloss:0.44691\n",
      "[86]\tvalidation-mlogloss:0.44653\n",
      "[87]\tvalidation-mlogloss:0.44627\n",
      "[88]\tvalidation-mlogloss:0.44615\n",
      "[89]\tvalidation-mlogloss:0.44613\n",
      "[90]\tvalidation-mlogloss:0.44638\n",
      "[91]\tvalidation-mlogloss:0.44573\n",
      "[92]\tvalidation-mlogloss:0.44585\n",
      "[93]\tvalidation-mlogloss:0.44698\n",
      "[94]\tvalidation-mlogloss:0.44764\n",
      "[95]\tvalidation-mlogloss:0.44678\n",
      "[96]\tvalidation-mlogloss:0.44711\n",
      "[97]\tvalidation-mlogloss:0.44719\n",
      "[98]\tvalidation-mlogloss:0.44726\n",
      "[99]\tvalidation-mlogloss:0.44733\n",
      "XGBoost 验证准确率: 0.8221\n",
      "XGBoost 测试准确率: 0.8054\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 将数据转换为 XGBoost 的 DMatrix 格式\n",
    "dtrain = xgb.DMatrix(train_features, label=train_labels)\n",
    "dvalid = xgb.DMatrix(validation_features, label=validation_labels)\n",
    "dtest = xgb.DMatrix(test_features, label=test_labels)\n",
    "\n",
    "# 设置 XGBoost 的参数\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # 用于多类分类\n",
    "    'num_class': num_classes,      # 类别数量\n",
    "    'eval_metric': 'mlogloss',     # 使用对数损失进行评估\n",
    "    'max_depth': 6,                # 树的最大深度\n",
    "    'eta': 0.1,                    # 学习率\n",
    "    'seed': 42                     # 随机种子\n",
    "}\n",
    "\n",
    "# 训练 XGBoost\n",
    "xgb_clf = xgb.train(params, dtrain, num_boost_round=100, evals=[(dvalid, 'validation')])\n",
    "\n",
    "# 验证 XGBoost\n",
    "validation_predictions_xgb = xgb_clf.predict(dvalid)\n",
    "validation_accuracy_xgb = accuracy_score(validation_labels, validation_predictions_xgb)\n",
    "print(f'XGBoost 验证准确率: {validation_accuracy_xgb:.4f}')\n",
    "\n",
    "# 测试 XGBoost\n",
    "test_predictions_xgb = xgb_clf.predict(dtest)\n",
    "test_accuracy_xgb = accuracy_score(test_labels, test_predictions_xgb)\n",
    "print(f'XGBoost 测试准确率: {test_accuracy_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-mlogloss:1.27678\n",
      "[1]\tvalidation-mlogloss:1.18596\n",
      "[2]\tvalidation-mlogloss:1.10482\n",
      "[3]\tvalidation-mlogloss:1.04226\n",
      "[4]\tvalidation-mlogloss:0.98213\n",
      "[5]\tvalidation-mlogloss:0.93216\n",
      "[6]\tvalidation-mlogloss:0.88883\n",
      "[7]\tvalidation-mlogloss:0.84934\n",
      "[8]\tvalidation-mlogloss:0.81408\n",
      "[9]\tvalidation-mlogloss:0.78427\n",
      "[10]\tvalidation-mlogloss:0.75769\n",
      "[11]\tvalidation-mlogloss:0.73029\n",
      "[12]\tvalidation-mlogloss:0.70713\n",
      "[13]\tvalidation-mlogloss:0.68498\n",
      "[14]\tvalidation-mlogloss:0.66780\n",
      "[15]\tvalidation-mlogloss:0.65096\n",
      "[16]\tvalidation-mlogloss:0.63548\n",
      "[17]\tvalidation-mlogloss:0.62268\n",
      "[18]\tvalidation-mlogloss:0.60741\n",
      "[19]\tvalidation-mlogloss:0.59614\n",
      "[20]\tvalidation-mlogloss:0.58516\n",
      "[21]\tvalidation-mlogloss:0.57563\n",
      "[22]\tvalidation-mlogloss:0.56677\n",
      "[23]\tvalidation-mlogloss:0.55617\n",
      "[24]\tvalidation-mlogloss:0.54900\n",
      "[25]\tvalidation-mlogloss:0.54136\n",
      "[26]\tvalidation-mlogloss:0.53531\n",
      "[27]\tvalidation-mlogloss:0.52940\n",
      "[28]\tvalidation-mlogloss:0.52493\n",
      "[29]\tvalidation-mlogloss:0.51896\n",
      "[30]\tvalidation-mlogloss:0.51194\n",
      "[31]\tvalidation-mlogloss:0.50789\n",
      "[32]\tvalidation-mlogloss:0.50391\n",
      "[33]\tvalidation-mlogloss:0.49898\n",
      "[34]\tvalidation-mlogloss:0.49437\n",
      "[35]\tvalidation-mlogloss:0.48992\n",
      "[36]\tvalidation-mlogloss:0.48554\n",
      "[37]\tvalidation-mlogloss:0.48322\n",
      "[38]\tvalidation-mlogloss:0.48133\n",
      "[39]\tvalidation-mlogloss:0.47946\n",
      "[40]\tvalidation-mlogloss:0.47884\n",
      "[41]\tvalidation-mlogloss:0.47695\n",
      "[42]\tvalidation-mlogloss:0.47559\n",
      "[43]\tvalidation-mlogloss:0.47215\n",
      "[44]\tvalidation-mlogloss:0.47073\n",
      "[45]\tvalidation-mlogloss:0.46899\n",
      "[46]\tvalidation-mlogloss:0.46770\n",
      "[47]\tvalidation-mlogloss:0.46694\n",
      "[48]\tvalidation-mlogloss:0.46541\n",
      "[49]\tvalidation-mlogloss:0.46427\n",
      "[50]\tvalidation-mlogloss:0.46405\n",
      "[51]\tvalidation-mlogloss:0.46223\n",
      "[52]\tvalidation-mlogloss:0.46159\n",
      "[53]\tvalidation-mlogloss:0.46062\n",
      "[54]\tvalidation-mlogloss:0.45974\n",
      "[55]\tvalidation-mlogloss:0.45977\n",
      "[56]\tvalidation-mlogloss:0.45902\n",
      "[57]\tvalidation-mlogloss:0.45819\n",
      "[58]\tvalidation-mlogloss:0.45560\n",
      "[59]\tvalidation-mlogloss:0.45469\n",
      "[60]\tvalidation-mlogloss:0.45156\n",
      "[61]\tvalidation-mlogloss:0.45165\n",
      "[62]\tvalidation-mlogloss:0.45264\n",
      "[63]\tvalidation-mlogloss:0.45221\n",
      "[64]\tvalidation-mlogloss:0.45172\n",
      "[65]\tvalidation-mlogloss:0.45058\n",
      "[66]\tvalidation-mlogloss:0.45069\n",
      "[67]\tvalidation-mlogloss:0.45056\n",
      "[68]\tvalidation-mlogloss:0.45023\n",
      "[69]\tvalidation-mlogloss:0.44917\n",
      "[70]\tvalidation-mlogloss:0.44919\n",
      "[71]\tvalidation-mlogloss:0.44948\n",
      "[72]\tvalidation-mlogloss:0.44890\n",
      "[73]\tvalidation-mlogloss:0.44907\n",
      "[74]\tvalidation-mlogloss:0.44920\n",
      "[75]\tvalidation-mlogloss:0.44883\n",
      "[76]\tvalidation-mlogloss:0.44820\n",
      "[77]\tvalidation-mlogloss:0.44798\n",
      "[78]\tvalidation-mlogloss:0.44881\n",
      "[79]\tvalidation-mlogloss:0.44768\n",
      "[80]\tvalidation-mlogloss:0.44738\n",
      "[81]\tvalidation-mlogloss:0.44694\n",
      "[82]\tvalidation-mlogloss:0.44722\n",
      "[83]\tvalidation-mlogloss:0.44669\n",
      "[84]\tvalidation-mlogloss:0.44662\n",
      "[85]\tvalidation-mlogloss:0.44691\n",
      "[86]\tvalidation-mlogloss:0.44653\n",
      "[87]\tvalidation-mlogloss:0.44627\n",
      "[88]\tvalidation-mlogloss:0.44615\n",
      "[89]\tvalidation-mlogloss:0.44613\n",
      "[90]\tvalidation-mlogloss:0.44638\n",
      "[91]\tvalidation-mlogloss:0.44573\n",
      "[92]\tvalidation-mlogloss:0.44585\n",
      "[93]\tvalidation-mlogloss:0.44698\n",
      "[94]\tvalidation-mlogloss:0.44764\n",
      "[95]\tvalidation-mlogloss:0.44678\n",
      "[96]\tvalidation-mlogloss:0.44711\n",
      "[97]\tvalidation-mlogloss:0.44719\n",
      "[98]\tvalidation-mlogloss:0.44726\n",
      "[99]\tvalidation-mlogloss:0.44733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 创建和训练 SVM\n",
    "svm_clf = SVC(kernel='linear', C=1, probability=True)  # 设置 probability=True 以输出概率\n",
    "svm_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 创建和训练 MLP\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "mlp_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 创建和训练 XGBoost\n",
    "dtrain = xgb.DMatrix(train_features, label=train_labels)\n",
    "dvalid = xgb.DMatrix(validation_features, label=validation_labels)\n",
    "dtest = xgb.DMatrix(test_features, label=test_labels)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # 使用 softprob 以输出概率\n",
    "    'num_class': num_classes,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "xgb_clf = xgb.train(params, dtrain, num_boost_round=100, evals=[(dvalid, 'validation')])\n",
    "\n",
    "# 获取各个模型在测试集上的预测概率\n",
    "svm_probs = svm_clf.predict_proba(test_features)\n",
    "mlp_probs = mlp_clf.predict_proba(test_features)\n",
    "xgb_probs = xgb_clf.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Test Accuracy: 0.8289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 创建 VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_clf),\n",
    "        ('mlp', mlp_clf),\n",
    "        # 为了让 VotingClassifier 支持 XGBoost，我们需要包装 XGBoost\n",
    "        ('xgb', xgb.XGBClassifier(objective='multi:softprob', n_estimators=100, max_depth=6, learning_rate=0.1))\n",
    "    ],\n",
    "    voting='soft',  # 使用软投票\n",
    "    weights=[1, 1, 1]  # 你可以根据需要调整权重\n",
    ")\n",
    "\n",
    "# 使用训练集进行训练\n",
    "voting_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "test_predictions_voting = voting_clf.predict(test_features)\n",
    "\n",
    "# 计算准确率\n",
    "voting_accuracy = accuracy_score(test_labels, test_predictions_voting)\n",
    "print(f'Voting Classifier Test Accuracy: {voting_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
