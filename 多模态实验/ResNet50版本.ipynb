{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class DualNPYDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir_rgb, root_dir_vessel, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir_rgb = root_dir_rgb\n",
    "        self.root_dir_vessel = root_dir_vessel\n",
    "        self.transform = transform\n",
    "\n",
    "        # 初始化LabelEncoder并对标签进行编码\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.encoded_labels = self.label_encoder.fit_transform(self.annotations.iloc[:, 2].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 加载RGB图像\n",
    "        img_name_rgb = os.path.join(self.root_dir_rgb, str(self.annotations.iloc[index, -1]) + '.npy')\n",
    "        image_rgb = np.load(img_name_rgb).astype(np.float32)  # 假设RGB图像是3通道的\n",
    "\n",
    "        # 加载血管分割后的二值图像\n",
    "        img_name_vessel = os.path.join(self.root_dir_vessel, str(self.annotations.iloc[index, -1]) + '.npy')\n",
    "        image_vessel = np.load(img_name_vessel).astype(np.float32)  # 假设血管分割图像是单通道的\n",
    "\n",
    "        # 扩展二值图像的维度并与RGB图像合并为4通道\n",
    "        image_vessel = np.expand_dims(image_vessel, axis=0)  # 从(H, W)变为(1, H, W)\n",
    "        image = np.concatenate((image_rgb, image_vessel), axis=0)  # 合并为(4, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.encoded_labels[index]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "# 定义图像转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 直接从(H, W, C)转为(C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406, 0.5], std=[0.229, 0.224, 0.225, 0.5])  # 归一化，假设第四个通道的均值和标准差为0.5\n",
    "])\n",
    "\n",
    "class DualInputResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DualInputResNet50, self).__init__()\n",
    "        # 定义ResNet50模型\n",
    "        self.resnet = timm.create_model('resnet50', pretrained=True, num_classes=0)\n",
    "        \n",
    "        # 修改第一个卷积层的输入通道为4\n",
    "        self.resnet.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # 定义分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),  # ResNet50的输出特征大小为2048\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 初始化数据集\n",
    "train_dataset = DualNPYDataset(csv_file='/kaggle/input/double-chanel-resnet50/train.csv',\n",
    "                               root_dir_gaussian='/kaggle/input/double-chanel-resnet50/resnet50_gaus_train/resnet50_gaus_train',\n",
    "                               root_dir_unet='/kaggle/input/double-chanel-resnet50/resnet50_predicted_train/resnet50_predicted_train',\n",
    "                               transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = DualNPYDataset(csv_file='/kaggle/input/double-chanel-resnet50/validation.csv',\n",
    "                               root_dir_rgb='/kaggle/input/double-chanel-resnet50/resnet50_rgb_validation',\n",
    "                               root_dir_vessel='/kaggle/input/double-chanel-resnet50/resnet50_vessel_validation',\n",
    "                               transform=transform)\n",
    "\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = DualNPYDataset(csv_file='/kaggle/input/double-chanel-resnet50/test.csv',\n",
    "                               root_dir_rgb='/kaggle/input/double-chanel-resnet50/resnet50_rgb_test',\n",
    "                               root_dir_vessel='/kaggle/input/double-chanel-resnet50/resnet50_vessel_test',\n",
    "                               transform=transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 模型初始化\n",
    "num_classes = len(np.unique(train_dataset.annotations['labels']))\n",
    "model = DualInputResNet50(num_classes=num_classes).to(device)\n",
    "\n",
    "# 创建一个权重数组，给第三类更高的权重\n",
    "weights = torch.tensor([1.0, 1.0, 1.0, 1.0], dtype=torch.float32).to(device)\n",
    "\n",
    "# 使用加权损失函数\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(loader, model, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (image_gaussian, image_unet), targets in loader:\n",
    "            image_gaussian, image_unet = image_gaussian.to(device), image_unet.to(device)\n",
    "            output = model((image_gaussian, image_unet))\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(targets.cpu().numpy())\n",
    "\n",
    "    features = np.concatenate(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播及优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, validation_loader, criterion, device):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = val_loss / len(validation_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/kaggle/working/trained_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 验证准确率: 0.962\n",
      "SVM 测试准确率: 0.954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 提取特征\n",
    "train_features, train_labels = extract_features(train_loader, model, device)\n",
    "validation_features, validation_labels = extract_features(validation_loader, model, device)\n",
    "test_features, test_labels = extract_features(test_loader, model, device)\n",
    "\n",
    "# 训练 SVM\n",
    "svm_clf = SVC(kernel='linear', C=1, probability=True)  # 设置 probability=True 以输出概率\n",
    "svm_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 验证 SVM\n",
    "validation_predictions_svm = svm_clf.predict(validation_features)\n",
    "validation_accuracy_svm = accuracy_score(validation_labels, validation_predictions_svm)\n",
    "print(f'SVM 验证准确率: {validation_accuracy_svm:.4f}')\n",
    "\n",
    "# 测试 SVM\n",
    "test_predictions_svm = svm_clf.predict(test_features)\n",
    "test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm)\n",
    "print(f'SVM 测试准确率: {test_accuracy_svm:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 验证准确率: 0.932\n",
      "MLP 测试准确率: 0.936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 训练 MLP\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "mlp_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 验证 MLP\n",
    "validation_predictions_mlp = mlp_clf.predict(validation_features)\n",
    "validation_accuracy_mlp = accuracy_score(validation_labels, validation_predictions_mlp)\n",
    "print(f'MLP 验证准确率: {validation_accuracy_mlp:.4f}')\n",
    "\n",
    "# 测试 MLP\n",
    "test_predictions_mlp = mlp_clf.predict(test_features)\n",
    "test_accuracy_mlp = accuracy_score(test_labels, test_predictions_mlp)\n",
    "print(f'MLP 测试准确率: {test_accuracy_mlp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB 验证准确率: 0.955\n",
      "XGB 测试准确率: 0.935\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 转换数据为 DMatrix 格式\n",
    "dtrain = xgb.DMatrix(train_features, label=train_labels)\n",
    "dvalid = xgb.DMatrix(validation_features, label=validation_labels)\n",
    "dtest = xgb.DMatrix(test_features, label=test_labels)\n",
    "\n",
    "# 设置参数\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # 用于多分类\n",
    "    'num_class': num_classes,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# 训练 XGBoost\n",
    "xgb_clf = xgb.train(params, dtrain, num_boost_round=100, evals=[(dvalid, 'validation')])\n",
    "\n",
    "# 验证 XGBoost\n",
    "validation_predictions_xgb = xgb_clf.predict(dvalid)\n",
    "validation_accuracy_xgb = accuracy_score(validation_labels, np.argmax(validation_predictions_xgb, axis=1))\n",
    "print(f'XGBoost 验证准确率: {validation_accuracy_xgb:.4f}')\n",
    "\n",
    "# 测试 XGBoost\n",
    "test_predictions_xgb = xgb_clf.predict(dtest)\n",
    "test_accuracy_xgb = accuracy_score(test_labels, np.argmax(test_predictions_xgb, axis=1))\n",
    "print(f'XGBoost 测试准确率: {test_accuracy_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 测试准确率: 0.992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 创建 VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_clf),\n",
    "        ('mlp', mlp_clf),\n",
    "        ('xgb', xgb.XGBClassifier(objective='multi:softprob', n_estimators=100, max_depth=6, learning_rate=0.1))\n",
    "    ],\n",
    "    voting='soft',  # 使用软投票\n",
    "    weights=[1, 1, 1]  # 根据需要调整权重\n",
    ")\n",
    "\n",
    "# 训练 VotingClassifier\n",
    "voting_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "test_predictions_voting = voting_clf.predict(test_features)\n",
    "\n",
    "# 计算最终准确率\n",
    "voting_accuracy = accuracy_score(test_labels, test_predictions_voting)\n",
    "print(f'Voting Classifier 测试准确率: {voting_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
