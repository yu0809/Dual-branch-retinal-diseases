{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T06:51:04.442668Z",
     "iopub.status.busy": "2024-08-07T06:51:04.442252Z",
     "iopub.status.idle": "2024-08-07T06:51:15.001668Z",
     "shell.execute_reply": "2024-08-07T06:51:15.000600Z",
     "shell.execute_reply.started": "2024-08-07T06:51:04.442621Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efaedabaedf14e578aed70a05b2a5e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有层的名称:\n",
      "\n",
      "swin_gaussian\n",
      "swin_gaussian.patch_embed\n",
      "swin_gaussian.patch_embed.proj\n",
      "swin_gaussian.patch_embed.norm\n",
      "swin_gaussian.layers\n",
      "swin_gaussian.layers.0\n",
      "swin_gaussian.layers.0.downsample\n",
      "swin_gaussian.layers.0.blocks\n",
      "swin_gaussian.layers.0.blocks.0\n",
      "swin_gaussian.layers.0.blocks.0.norm1\n",
      "swin_gaussian.layers.0.blocks.0.attn\n",
      "swin_gaussian.layers.0.blocks.0.attn.qkv\n",
      "swin_gaussian.layers.0.blocks.0.attn.attn_drop\n",
      "swin_gaussian.layers.0.blocks.0.attn.proj\n",
      "swin_gaussian.layers.0.blocks.0.attn.proj_drop\n",
      "swin_gaussian.layers.0.blocks.0.attn.softmax\n",
      "swin_gaussian.layers.0.blocks.0.drop_path1\n",
      "swin_gaussian.layers.0.blocks.0.norm2\n",
      "swin_gaussian.layers.0.blocks.0.mlp\n",
      "swin_gaussian.layers.0.blocks.0.mlp.fc1\n",
      "swin_gaussian.layers.0.blocks.0.mlp.act\n",
      "swin_gaussian.layers.0.blocks.0.mlp.drop1\n",
      "swin_gaussian.layers.0.blocks.0.mlp.norm\n",
      "swin_gaussian.layers.0.blocks.0.mlp.fc2\n",
      "swin_gaussian.layers.0.blocks.0.mlp.drop2\n",
      "swin_gaussian.layers.0.blocks.0.drop_path2\n",
      "swin_gaussian.layers.0.blocks.1\n",
      "swin_gaussian.layers.0.blocks.1.norm1\n",
      "swin_gaussian.layers.0.blocks.1.attn\n",
      "swin_gaussian.layers.0.blocks.1.attn.qkv\n",
      "swin_gaussian.layers.0.blocks.1.attn.attn_drop\n",
      "swin_gaussian.layers.0.blocks.1.attn.proj\n",
      "swin_gaussian.layers.0.blocks.1.attn.proj_drop\n",
      "swin_gaussian.layers.0.blocks.1.attn.softmax\n",
      "swin_gaussian.layers.0.blocks.1.drop_path1\n",
      "swin_gaussian.layers.0.blocks.1.norm2\n",
      "swin_gaussian.layers.0.blocks.1.mlp\n",
      "swin_gaussian.layers.0.blocks.1.mlp.fc1\n",
      "swin_gaussian.layers.0.blocks.1.mlp.act\n",
      "swin_gaussian.layers.0.blocks.1.mlp.drop1\n",
      "swin_gaussian.layers.0.blocks.1.mlp.norm\n",
      "swin_gaussian.layers.0.blocks.1.mlp.fc2\n",
      "swin_gaussian.layers.0.blocks.1.mlp.drop2\n",
      "swin_gaussian.layers.0.blocks.1.drop_path2\n",
      "swin_gaussian.layers.1\n",
      "swin_gaussian.layers.1.downsample\n",
      "swin_gaussian.layers.1.downsample.norm\n",
      "swin_gaussian.layers.1.downsample.reduction\n",
      "swin_gaussian.layers.1.blocks\n",
      "swin_gaussian.layers.1.blocks.0\n",
      "swin_gaussian.layers.1.blocks.0.norm1\n",
      "swin_gaussian.layers.1.blocks.0.attn\n",
      "swin_gaussian.layers.1.blocks.0.attn.qkv\n",
      "swin_gaussian.layers.1.blocks.0.attn.attn_drop\n",
      "swin_gaussian.layers.1.blocks.0.attn.proj\n",
      "swin_gaussian.layers.1.blocks.0.attn.proj_drop\n",
      "swin_gaussian.layers.1.blocks.0.attn.softmax\n",
      "swin_gaussian.layers.1.blocks.0.drop_path1\n",
      "swin_gaussian.layers.1.blocks.0.norm2\n",
      "swin_gaussian.layers.1.blocks.0.mlp\n",
      "swin_gaussian.layers.1.blocks.0.mlp.fc1\n",
      "swin_gaussian.layers.1.blocks.0.mlp.act\n",
      "swin_gaussian.layers.1.blocks.0.mlp.drop1\n",
      "swin_gaussian.layers.1.blocks.0.mlp.norm\n",
      "swin_gaussian.layers.1.blocks.0.mlp.fc2\n",
      "swin_gaussian.layers.1.blocks.0.mlp.drop2\n",
      "swin_gaussian.layers.1.blocks.0.drop_path2\n",
      "swin_gaussian.layers.1.blocks.1\n",
      "swin_gaussian.layers.1.blocks.1.norm1\n",
      "swin_gaussian.layers.1.blocks.1.attn\n",
      "swin_gaussian.layers.1.blocks.1.attn.qkv\n",
      "swin_gaussian.layers.1.blocks.1.attn.attn_drop\n",
      "swin_gaussian.layers.1.blocks.1.attn.proj\n",
      "swin_gaussian.layers.1.blocks.1.attn.proj_drop\n",
      "swin_gaussian.layers.1.blocks.1.attn.softmax\n",
      "swin_gaussian.layers.1.blocks.1.drop_path1\n",
      "swin_gaussian.layers.1.blocks.1.norm2\n",
      "swin_gaussian.layers.1.blocks.1.mlp\n",
      "swin_gaussian.layers.1.blocks.1.mlp.fc1\n",
      "swin_gaussian.layers.1.blocks.1.mlp.act\n",
      "swin_gaussian.layers.1.blocks.1.mlp.drop1\n",
      "swin_gaussian.layers.1.blocks.1.mlp.norm\n",
      "swin_gaussian.layers.1.blocks.1.mlp.fc2\n",
      "swin_gaussian.layers.1.blocks.1.mlp.drop2\n",
      "swin_gaussian.layers.1.blocks.1.drop_path2\n",
      "swin_gaussian.layers.2\n",
      "swin_gaussian.layers.2.downsample\n",
      "swin_gaussian.layers.2.downsample.norm\n",
      "swin_gaussian.layers.2.downsample.reduction\n",
      "swin_gaussian.layers.2.blocks\n",
      "swin_gaussian.layers.2.blocks.0\n",
      "swin_gaussian.layers.2.blocks.0.norm1\n",
      "swin_gaussian.layers.2.blocks.0.attn\n",
      "swin_gaussian.layers.2.blocks.0.attn.qkv\n",
      "swin_gaussian.layers.2.blocks.0.attn.attn_drop\n",
      "swin_gaussian.layers.2.blocks.0.attn.proj\n",
      "swin_gaussian.layers.2.blocks.0.attn.proj_drop\n",
      "swin_gaussian.layers.2.blocks.0.attn.softmax\n",
      "swin_gaussian.layers.2.blocks.0.drop_path1\n",
      "swin_gaussian.layers.2.blocks.0.norm2\n",
      "swin_gaussian.layers.2.blocks.0.mlp\n",
      "swin_gaussian.layers.2.blocks.0.mlp.fc1\n",
      "swin_gaussian.layers.2.blocks.0.mlp.act\n",
      "swin_gaussian.layers.2.blocks.0.mlp.drop1\n",
      "swin_gaussian.layers.2.blocks.0.mlp.norm\n",
      "swin_gaussian.layers.2.blocks.0.mlp.fc2\n",
      "swin_gaussian.layers.2.blocks.0.mlp.drop2\n",
      "swin_gaussian.layers.2.blocks.0.drop_path2\n",
      "swin_gaussian.layers.2.blocks.1\n",
      "swin_gaussian.layers.2.blocks.1.norm1\n",
      "swin_gaussian.layers.2.blocks.1.attn\n",
      "swin_gaussian.layers.2.blocks.1.attn.qkv\n",
      "swin_gaussian.layers.2.blocks.1.attn.attn_drop\n",
      "swin_gaussian.layers.2.blocks.1.attn.proj\n",
      "swin_gaussian.layers.2.blocks.1.attn.proj_drop\n",
      "swin_gaussian.layers.2.blocks.1.attn.softmax\n",
      "swin_gaussian.layers.2.blocks.1.drop_path1\n",
      "swin_gaussian.layers.2.blocks.1.norm2\n",
      "swin_gaussian.layers.2.blocks.1.mlp\n",
      "swin_gaussian.layers.2.blocks.1.mlp.fc1\n",
      "swin_gaussian.layers.2.blocks.1.mlp.act\n",
      "swin_gaussian.layers.2.blocks.1.mlp.drop1\n",
      "swin_gaussian.layers.2.blocks.1.mlp.norm\n",
      "swin_gaussian.layers.2.blocks.1.mlp.fc2\n",
      "swin_gaussian.layers.2.blocks.1.mlp.drop2\n",
      "swin_gaussian.layers.2.blocks.1.drop_path2\n",
      "swin_gaussian.layers.2.blocks.2\n",
      "swin_gaussian.layers.2.blocks.2.norm1\n",
      "swin_gaussian.layers.2.blocks.2.attn\n",
      "swin_gaussian.layers.2.blocks.2.attn.qkv\n",
      "swin_gaussian.layers.2.blocks.2.attn.attn_drop\n",
      "swin_gaussian.layers.2.blocks.2.attn.proj\n",
      "swin_gaussian.layers.2.blocks.2.attn.proj_drop\n",
      "swin_gaussian.layers.2.blocks.2.attn.softmax\n",
      "swin_gaussian.layers.2.blocks.2.drop_path1\n",
      "swin_gaussian.layers.2.blocks.2.norm2\n",
      "swin_gaussian.layers.2.blocks.2.mlp\n",
      "swin_gaussian.layers.2.blocks.2.mlp.fc1\n",
      "swin_gaussian.layers.2.blocks.2.mlp.act\n",
      "swin_gaussian.layers.2.blocks.2.mlp.drop1\n",
      "swin_gaussian.layers.2.blocks.2.mlp.norm\n",
      "swin_gaussian.layers.2.blocks.2.mlp.fc2\n",
      "swin_gaussian.layers.2.blocks.2.mlp.drop2\n",
      "swin_gaussian.layers.2.blocks.2.drop_path2\n",
      "swin_gaussian.layers.2.blocks.3\n",
      "swin_gaussian.layers.2.blocks.3.norm1\n",
      "swin_gaussian.layers.2.blocks.3.attn\n",
      "swin_gaussian.layers.2.blocks.3.attn.qkv\n",
      "swin_gaussian.layers.2.blocks.3.attn.attn_drop\n",
      "swin_gaussian.layers.2.blocks.3.attn.proj\n",
      "swin_gaussian.layers.2.blocks.3.attn.proj_drop\n",
      "swin_gaussian.layers.2.blocks.3.attn.softmax\n",
      "swin_gaussian.layers.2.blocks.3.drop_path1\n",
      "swin_gaussian.layers.2.blocks.3.norm2\n",
      "swin_gaussian.layers.2.blocks.3.mlp\n",
      "swin_gaussian.layers.2.blocks.3.mlp.fc1\n",
      "swin_gaussian.layers.2.blocks.3.mlp.act\n",
      "swin_gaussian.layers.2.blocks.3.mlp.drop1\n",
      "swin_gaussian.layers.2.blocks.3.mlp.norm\n",
      "swin_gaussian.layers.2.blocks.3.mlp.fc2\n",
      "swin_gaussian.layers.2.blocks.3.mlp.drop2\n",
      "swin_gaussian.layers.2.blocks.3.drop_path2\n",
      "swin_gaussian.layers.2.blocks.4\n",
      "swin_gaussian.layers.2.blocks.4.norm1\n",
      "swin_gaussian.layers.2.blocks.4.attn\n",
      "swin_gaussian.layers.2.blocks.4.attn.qkv\n",
      "swin_gaussian.layers.2.blocks.4.attn.attn_drop\n",
      "swin_gaussian.layers.2.blocks.4.attn.proj\n",
      "swin_gaussian.layers.2.blocks.4.attn.proj_drop\n",
      "swin_gaussian.layers.2.blocks.4.attn.softmax\n",
      "swin_gaussian.layers.2.blocks.4.drop_path1\n",
      "swin_gaussian.layers.2.blocks.4.norm2\n",
      "swin_gaussian.layers.2.blocks.4.mlp\n",
      "swin_gaussian.layers.2.blocks.4.mlp.fc1\n",
      "swin_gaussian.layers.2.blocks.4.mlp.act\n",
      "swin_gaussian.layers.2.blocks.4.mlp.drop1\n",
      "swin_gaussian.layers.2.blocks.4.mlp.norm\n",
      "swin_gaussian.layers.2.blocks.4.mlp.fc2\n",
      "swin_gaussian.layers.2.blocks.4.mlp.drop2\n",
      "swin_gaussian.layers.2.blocks.4.drop_path2\n",
      "swin_gaussian.layers.2.blocks.5\n",
      "swin_gaussian.layers.2.blocks.5.norm1\n",
      "swin_gaussian.layers.2.blocks.5.attn\n",
      "swin_gaussian.layers.2.blocks.5.attn.qkv\n",
      "swin_gaussian.layers.2.blocks.5.attn.attn_drop\n",
      "swin_gaussian.layers.2.blocks.5.attn.proj\n",
      "swin_gaussian.layers.2.blocks.5.attn.proj_drop\n",
      "swin_gaussian.layers.2.blocks.5.attn.softmax\n",
      "swin_gaussian.layers.2.blocks.5.drop_path1\n",
      "swin_gaussian.layers.2.blocks.5.norm2\n",
      "swin_gaussian.layers.2.blocks.5.mlp\n",
      "swin_gaussian.layers.2.blocks.5.mlp.fc1\n",
      "swin_gaussian.layers.2.blocks.5.mlp.act\n",
      "swin_gaussian.layers.2.blocks.5.mlp.drop1\n",
      "swin_gaussian.layers.2.blocks.5.mlp.norm\n",
      "swin_gaussian.layers.2.blocks.5.mlp.fc2\n",
      "swin_gaussian.layers.2.blocks.5.mlp.drop2\n",
      "swin_gaussian.layers.2.blocks.5.drop_path2\n",
      "swin_gaussian.layers.3\n",
      "swin_gaussian.layers.3.downsample\n",
      "swin_gaussian.layers.3.downsample.norm\n",
      "swin_gaussian.layers.3.downsample.reduction\n",
      "swin_gaussian.layers.3.blocks\n",
      "swin_gaussian.layers.3.blocks.0\n",
      "swin_gaussian.layers.3.blocks.0.norm1\n",
      "swin_gaussian.layers.3.blocks.0.attn\n",
      "swin_gaussian.layers.3.blocks.0.attn.qkv\n",
      "swin_gaussian.layers.3.blocks.0.attn.attn_drop\n",
      "swin_gaussian.layers.3.blocks.0.attn.proj\n",
      "swin_gaussian.layers.3.blocks.0.attn.proj_drop\n",
      "swin_gaussian.layers.3.blocks.0.attn.softmax\n",
      "swin_gaussian.layers.3.blocks.0.drop_path1\n",
      "swin_gaussian.layers.3.blocks.0.norm2\n",
      "swin_gaussian.layers.3.blocks.0.mlp\n",
      "swin_gaussian.layers.3.blocks.0.mlp.fc1\n",
      "swin_gaussian.layers.3.blocks.0.mlp.act\n",
      "swin_gaussian.layers.3.blocks.0.mlp.drop1\n",
      "swin_gaussian.layers.3.blocks.0.mlp.norm\n",
      "swin_gaussian.layers.3.blocks.0.mlp.fc2\n",
      "swin_gaussian.layers.3.blocks.0.mlp.drop2\n",
      "swin_gaussian.layers.3.blocks.0.drop_path2\n",
      "swin_gaussian.layers.3.blocks.1\n",
      "swin_gaussian.layers.3.blocks.1.norm1\n",
      "swin_gaussian.layers.3.blocks.1.attn\n",
      "swin_gaussian.layers.3.blocks.1.attn.qkv\n",
      "swin_gaussian.layers.3.blocks.1.attn.attn_drop\n",
      "swin_gaussian.layers.3.blocks.1.attn.proj\n",
      "swin_gaussian.layers.3.blocks.1.attn.proj_drop\n",
      "swin_gaussian.layers.3.blocks.1.attn.softmax\n",
      "swin_gaussian.layers.3.blocks.1.drop_path1\n",
      "swin_gaussian.layers.3.blocks.1.norm2\n",
      "swin_gaussian.layers.3.blocks.1.mlp\n",
      "swin_gaussian.layers.3.blocks.1.mlp.fc1\n",
      "swin_gaussian.layers.3.blocks.1.mlp.act\n",
      "swin_gaussian.layers.3.blocks.1.mlp.drop1\n",
      "swin_gaussian.layers.3.blocks.1.mlp.norm\n",
      "swin_gaussian.layers.3.blocks.1.mlp.fc2\n",
      "swin_gaussian.layers.3.blocks.1.mlp.drop2\n",
      "swin_gaussian.layers.3.blocks.1.drop_path2\n",
      "swin_gaussian.norm\n",
      "swin_gaussian.head\n",
      "swin_gaussian.head.global_pool\n",
      "swin_gaussian.head.global_pool.pool\n",
      "swin_gaussian.head.global_pool.flatten\n",
      "swin_gaussian.head.drop\n",
      "swin_gaussian.head.fc\n",
      "swin_gaussian.head.flatten\n",
      "swin_unet\n",
      "swin_unet.patch_embed\n",
      "swin_unet.patch_embed.proj\n",
      "swin_unet.patch_embed.norm\n",
      "swin_unet.layers\n",
      "swin_unet.layers.0\n",
      "swin_unet.layers.0.downsample\n",
      "swin_unet.layers.0.blocks\n",
      "swin_unet.layers.0.blocks.0\n",
      "swin_unet.layers.0.blocks.0.norm1\n",
      "swin_unet.layers.0.blocks.0.attn\n",
      "swin_unet.layers.0.blocks.0.attn.qkv\n",
      "swin_unet.layers.0.blocks.0.attn.attn_drop\n",
      "swin_unet.layers.0.blocks.0.attn.proj\n",
      "swin_unet.layers.0.blocks.0.attn.proj_drop\n",
      "swin_unet.layers.0.blocks.0.attn.softmax\n",
      "swin_unet.layers.0.blocks.0.drop_path1\n",
      "swin_unet.layers.0.blocks.0.norm2\n",
      "swin_unet.layers.0.blocks.0.mlp\n",
      "swin_unet.layers.0.blocks.0.mlp.fc1\n",
      "swin_unet.layers.0.blocks.0.mlp.act\n",
      "swin_unet.layers.0.blocks.0.mlp.drop1\n",
      "swin_unet.layers.0.blocks.0.mlp.norm\n",
      "swin_unet.layers.0.blocks.0.mlp.fc2\n",
      "swin_unet.layers.0.blocks.0.mlp.drop2\n",
      "swin_unet.layers.0.blocks.0.drop_path2\n",
      "swin_unet.layers.0.blocks.1\n",
      "swin_unet.layers.0.blocks.1.norm1\n",
      "swin_unet.layers.0.blocks.1.attn\n",
      "swin_unet.layers.0.blocks.1.attn.qkv\n",
      "swin_unet.layers.0.blocks.1.attn.attn_drop\n",
      "swin_unet.layers.0.blocks.1.attn.proj\n",
      "swin_unet.layers.0.blocks.1.attn.proj_drop\n",
      "swin_unet.layers.0.blocks.1.attn.softmax\n",
      "swin_unet.layers.0.blocks.1.drop_path1\n",
      "swin_unet.layers.0.blocks.1.norm2\n",
      "swin_unet.layers.0.blocks.1.mlp\n",
      "swin_unet.layers.0.blocks.1.mlp.fc1\n",
      "swin_unet.layers.0.blocks.1.mlp.act\n",
      "swin_unet.layers.0.blocks.1.mlp.drop1\n",
      "swin_unet.layers.0.blocks.1.mlp.norm\n",
      "swin_unet.layers.0.blocks.1.mlp.fc2\n",
      "swin_unet.layers.0.blocks.1.mlp.drop2\n",
      "swin_unet.layers.0.blocks.1.drop_path2\n",
      "swin_unet.layers.1\n",
      "swin_unet.layers.1.downsample\n",
      "swin_unet.layers.1.downsample.norm\n",
      "swin_unet.layers.1.downsample.reduction\n",
      "swin_unet.layers.1.blocks\n",
      "swin_unet.layers.1.blocks.0\n",
      "swin_unet.layers.1.blocks.0.norm1\n",
      "swin_unet.layers.1.blocks.0.attn\n",
      "swin_unet.layers.1.blocks.0.attn.qkv\n",
      "swin_unet.layers.1.blocks.0.attn.attn_drop\n",
      "swin_unet.layers.1.blocks.0.attn.proj\n",
      "swin_unet.layers.1.blocks.0.attn.proj_drop\n",
      "swin_unet.layers.1.blocks.0.attn.softmax\n",
      "swin_unet.layers.1.blocks.0.drop_path1\n",
      "swin_unet.layers.1.blocks.0.norm2\n",
      "swin_unet.layers.1.blocks.0.mlp\n",
      "swin_unet.layers.1.blocks.0.mlp.fc1\n",
      "swin_unet.layers.1.blocks.0.mlp.act\n",
      "swin_unet.layers.1.blocks.0.mlp.drop1\n",
      "swin_unet.layers.1.blocks.0.mlp.norm\n",
      "swin_unet.layers.1.blocks.0.mlp.fc2\n",
      "swin_unet.layers.1.blocks.0.mlp.drop2\n",
      "swin_unet.layers.1.blocks.0.drop_path2\n",
      "swin_unet.layers.1.blocks.1\n",
      "swin_unet.layers.1.blocks.1.norm1\n",
      "swin_unet.layers.1.blocks.1.attn\n",
      "swin_unet.layers.1.blocks.1.attn.qkv\n",
      "swin_unet.layers.1.blocks.1.attn.attn_drop\n",
      "swin_unet.layers.1.blocks.1.attn.proj\n",
      "swin_unet.layers.1.blocks.1.attn.proj_drop\n",
      "swin_unet.layers.1.blocks.1.attn.softmax\n",
      "swin_unet.layers.1.blocks.1.drop_path1\n",
      "swin_unet.layers.1.blocks.1.norm2\n",
      "swin_unet.layers.1.blocks.1.mlp\n",
      "swin_unet.layers.1.blocks.1.mlp.fc1\n",
      "swin_unet.layers.1.blocks.1.mlp.act\n",
      "swin_unet.layers.1.blocks.1.mlp.drop1\n",
      "swin_unet.layers.1.blocks.1.mlp.norm\n",
      "swin_unet.layers.1.blocks.1.mlp.fc2\n",
      "swin_unet.layers.1.blocks.1.mlp.drop2\n",
      "swin_unet.layers.1.blocks.1.drop_path2\n",
      "swin_unet.layers.2\n",
      "swin_unet.layers.2.downsample\n",
      "swin_unet.layers.2.downsample.norm\n",
      "swin_unet.layers.2.downsample.reduction\n",
      "swin_unet.layers.2.blocks\n",
      "swin_unet.layers.2.blocks.0\n",
      "swin_unet.layers.2.blocks.0.norm1\n",
      "swin_unet.layers.2.blocks.0.attn\n",
      "swin_unet.layers.2.blocks.0.attn.qkv\n",
      "swin_unet.layers.2.blocks.0.attn.attn_drop\n",
      "swin_unet.layers.2.blocks.0.attn.proj\n",
      "swin_unet.layers.2.blocks.0.attn.proj_drop\n",
      "swin_unet.layers.2.blocks.0.attn.softmax\n",
      "swin_unet.layers.2.blocks.0.drop_path1\n",
      "swin_unet.layers.2.blocks.0.norm2\n",
      "swin_unet.layers.2.blocks.0.mlp\n",
      "swin_unet.layers.2.blocks.0.mlp.fc1\n",
      "swin_unet.layers.2.blocks.0.mlp.act\n",
      "swin_unet.layers.2.blocks.0.mlp.drop1\n",
      "swin_unet.layers.2.blocks.0.mlp.norm\n",
      "swin_unet.layers.2.blocks.0.mlp.fc2\n",
      "swin_unet.layers.2.blocks.0.mlp.drop2\n",
      "swin_unet.layers.2.blocks.0.drop_path2\n",
      "swin_unet.layers.2.blocks.1\n",
      "swin_unet.layers.2.blocks.1.norm1\n",
      "swin_unet.layers.2.blocks.1.attn\n",
      "swin_unet.layers.2.blocks.1.attn.qkv\n",
      "swin_unet.layers.2.blocks.1.attn.attn_drop\n",
      "swin_unet.layers.2.blocks.1.attn.proj\n",
      "swin_unet.layers.2.blocks.1.attn.proj_drop\n",
      "swin_unet.layers.2.blocks.1.attn.softmax\n",
      "swin_unet.layers.2.blocks.1.drop_path1\n",
      "swin_unet.layers.2.blocks.1.norm2\n",
      "swin_unet.layers.2.blocks.1.mlp\n",
      "swin_unet.layers.2.blocks.1.mlp.fc1\n",
      "swin_unet.layers.2.blocks.1.mlp.act\n",
      "swin_unet.layers.2.blocks.1.mlp.drop1\n",
      "swin_unet.layers.2.blocks.1.mlp.norm\n",
      "swin_unet.layers.2.blocks.1.mlp.fc2\n",
      "swin_unet.layers.2.blocks.1.mlp.drop2\n",
      "swin_unet.layers.2.blocks.1.drop_path2\n",
      "swin_unet.layers.2.blocks.2\n",
      "swin_unet.layers.2.blocks.2.norm1\n",
      "swin_unet.layers.2.blocks.2.attn\n",
      "swin_unet.layers.2.blocks.2.attn.qkv\n",
      "swin_unet.layers.2.blocks.2.attn.attn_drop\n",
      "swin_unet.layers.2.blocks.2.attn.proj\n",
      "swin_unet.layers.2.blocks.2.attn.proj_drop\n",
      "swin_unet.layers.2.blocks.2.attn.softmax\n",
      "swin_unet.layers.2.blocks.2.drop_path1\n",
      "swin_unet.layers.2.blocks.2.norm2\n",
      "swin_unet.layers.2.blocks.2.mlp\n",
      "swin_unet.layers.2.blocks.2.mlp.fc1\n",
      "swin_unet.layers.2.blocks.2.mlp.act\n",
      "swin_unet.layers.2.blocks.2.mlp.drop1\n",
      "swin_unet.layers.2.blocks.2.mlp.norm\n",
      "swin_unet.layers.2.blocks.2.mlp.fc2\n",
      "swin_unet.layers.2.blocks.2.mlp.drop2\n",
      "swin_unet.layers.2.blocks.2.drop_path2\n",
      "swin_unet.layers.2.blocks.3\n",
      "swin_unet.layers.2.blocks.3.norm1\n",
      "swin_unet.layers.2.blocks.3.attn\n",
      "swin_unet.layers.2.blocks.3.attn.qkv\n",
      "swin_unet.layers.2.blocks.3.attn.attn_drop\n",
      "swin_unet.layers.2.blocks.3.attn.proj\n",
      "swin_unet.layers.2.blocks.3.attn.proj_drop\n",
      "swin_unet.layers.2.blocks.3.attn.softmax\n",
      "swin_unet.layers.2.blocks.3.drop_path1\n",
      "swin_unet.layers.2.blocks.3.norm2\n",
      "swin_unet.layers.2.blocks.3.mlp\n",
      "swin_unet.layers.2.blocks.3.mlp.fc1\n",
      "swin_unet.layers.2.blocks.3.mlp.act\n",
      "swin_unet.layers.2.blocks.3.mlp.drop1\n",
      "swin_unet.layers.2.blocks.3.mlp.norm\n",
      "swin_unet.layers.2.blocks.3.mlp.fc2\n",
      "swin_unet.layers.2.blocks.3.mlp.drop2\n",
      "swin_unet.layers.2.blocks.3.drop_path2\n",
      "swin_unet.layers.2.blocks.4\n",
      "swin_unet.layers.2.blocks.4.norm1\n",
      "swin_unet.layers.2.blocks.4.attn\n",
      "swin_unet.layers.2.blocks.4.attn.qkv\n",
      "swin_unet.layers.2.blocks.4.attn.attn_drop\n",
      "swin_unet.layers.2.blocks.4.attn.proj\n",
      "swin_unet.layers.2.blocks.4.attn.proj_drop\n",
      "swin_unet.layers.2.blocks.4.attn.softmax\n",
      "swin_unet.layers.2.blocks.4.drop_path1\n",
      "swin_unet.layers.2.blocks.4.norm2\n",
      "swin_unet.layers.2.blocks.4.mlp\n",
      "swin_unet.layers.2.blocks.4.mlp.fc1\n",
      "swin_unet.layers.2.blocks.4.mlp.act\n",
      "swin_unet.layers.2.blocks.4.mlp.drop1\n",
      "swin_unet.layers.2.blocks.4.mlp.norm\n",
      "swin_unet.layers.2.blocks.4.mlp.fc2\n",
      "swin_unet.layers.2.blocks.4.mlp.drop2\n",
      "swin_unet.layers.2.blocks.4.drop_path2\n",
      "swin_unet.layers.2.blocks.5\n",
      "swin_unet.layers.2.blocks.5.norm1\n",
      "swin_unet.layers.2.blocks.5.attn\n",
      "swin_unet.layers.2.blocks.5.attn.qkv\n",
      "swin_unet.layers.2.blocks.5.attn.attn_drop\n",
      "swin_unet.layers.2.blocks.5.attn.proj\n",
      "swin_unet.layers.2.blocks.5.attn.proj_drop\n",
      "swin_unet.layers.2.blocks.5.attn.softmax\n",
      "swin_unet.layers.2.blocks.5.drop_path1\n",
      "swin_unet.layers.2.blocks.5.norm2\n",
      "swin_unet.layers.2.blocks.5.mlp\n",
      "swin_unet.layers.2.blocks.5.mlp.fc1\n",
      "swin_unet.layers.2.blocks.5.mlp.act\n",
      "swin_unet.layers.2.blocks.5.mlp.drop1\n",
      "swin_unet.layers.2.blocks.5.mlp.norm\n",
      "swin_unet.layers.2.blocks.5.mlp.fc2\n",
      "swin_unet.layers.2.blocks.5.mlp.drop2\n",
      "swin_unet.layers.2.blocks.5.drop_path2\n",
      "swin_unet.layers.3\n",
      "swin_unet.layers.3.downsample\n",
      "swin_unet.layers.3.downsample.norm\n",
      "swin_unet.layers.3.downsample.reduction\n",
      "swin_unet.layers.3.blocks\n",
      "swin_unet.layers.3.blocks.0\n",
      "swin_unet.layers.3.blocks.0.norm1\n",
      "swin_unet.layers.3.blocks.0.attn\n",
      "swin_unet.layers.3.blocks.0.attn.qkv\n",
      "swin_unet.layers.3.blocks.0.attn.attn_drop\n",
      "swin_unet.layers.3.blocks.0.attn.proj\n",
      "swin_unet.layers.3.blocks.0.attn.proj_drop\n",
      "swin_unet.layers.3.blocks.0.attn.softmax\n",
      "swin_unet.layers.3.blocks.0.drop_path1\n",
      "swin_unet.layers.3.blocks.0.norm2\n",
      "swin_unet.layers.3.blocks.0.mlp\n",
      "swin_unet.layers.3.blocks.0.mlp.fc1\n",
      "swin_unet.layers.3.blocks.0.mlp.act\n",
      "swin_unet.layers.3.blocks.0.mlp.drop1\n",
      "swin_unet.layers.3.blocks.0.mlp.norm\n",
      "swin_unet.layers.3.blocks.0.mlp.fc2\n",
      "swin_unet.layers.3.blocks.0.mlp.drop2\n",
      "swin_unet.layers.3.blocks.0.drop_path2\n",
      "swin_unet.layers.3.blocks.1\n",
      "swin_unet.layers.3.blocks.1.norm1\n",
      "swin_unet.layers.3.blocks.1.attn\n",
      "swin_unet.layers.3.blocks.1.attn.qkv\n",
      "swin_unet.layers.3.blocks.1.attn.attn_drop\n",
      "swin_unet.layers.3.blocks.1.attn.proj\n",
      "swin_unet.layers.3.blocks.1.attn.proj_drop\n",
      "swin_unet.layers.3.blocks.1.attn.softmax\n",
      "swin_unet.layers.3.blocks.1.drop_path1\n",
      "swin_unet.layers.3.blocks.1.norm2\n",
      "swin_unet.layers.3.blocks.1.mlp\n",
      "swin_unet.layers.3.blocks.1.mlp.fc1\n",
      "swin_unet.layers.3.blocks.1.mlp.act\n",
      "swin_unet.layers.3.blocks.1.mlp.drop1\n",
      "swin_unet.layers.3.blocks.1.mlp.norm\n",
      "swin_unet.layers.3.blocks.1.mlp.fc2\n",
      "swin_unet.layers.3.blocks.1.mlp.drop2\n",
      "swin_unet.layers.3.blocks.1.drop_path2\n",
      "swin_unet.norm\n",
      "swin_unet.head\n",
      "swin_unet.head.global_pool\n",
      "swin_unet.head.global_pool.pool\n",
      "swin_unet.head.global_pool.flatten\n",
      "swin_unet.head.drop\n",
      "swin_unet.head.fc\n",
      "swin_unet.head.flatten\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.1\n",
      "classifier.2\n",
      "classifier.3\n",
      "\n",
      "最后两层的名称:\n",
      "['classifier.2', 'classifier.3']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "class DualInputSwinTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DualInputSwinTransformer, self).__init__()\n",
    "        # 定义两个独立的Swin Transformer模型作为编码器\n",
    "        self.swin_gaussian = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=0)\n",
    "        self.swin_unet = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=0)\n",
    "        \n",
    "        # 定义一个分类器，将两个编码器的输出合并后进行分类\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 * 2, 512),  # 假设每个Swin Transformer的输出特征大小为768\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x\n",
    "        x1 = self.swin_gaussian(x1)\n",
    "        x2 = self.swin_unet(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)  # 在特征维度上合并两个编码器的输出\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = DualInputSwinTransformer(num_classes=100)\n",
    "\n",
    "# 打印所有层的名称\n",
    "print(\"所有层的名称:\")\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "\n",
    "# 找到并打印最后两层的名称\n",
    "layer_names = [name for name, _ in model.named_modules()]\n",
    "if len(layer_names) >= 2:\n",
    "    print(\"\\n最后两层的名称:\")\n",
    "    print(layer_names[-2:])\n",
    "else:\n",
    "    print(\"模型中没有足够的层来显示最后两层的名称\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T07:11:06.316316Z",
     "iopub.status.busy": "2024-08-07T07:11:06.315643Z",
     "iopub.status.idle": "2024-08-07T07:11:07.810143Z",
     "shell.execute_reply": "2024-08-07T07:11:07.809273Z",
     "shell.execute_reply.started": "2024-08-07T07:11:06.316283Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class DualNPYDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir_gaussian, root_dir_unet, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir_gaussian = root_dir_gaussian\n",
    "        self.root_dir_unet = root_dir_unet\n",
    "        self.transform = transform\n",
    "\n",
    "        # 初始化LabelEncoder并对标签进行编码\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # 假设标签在CSV文件的第三列\n",
    "        self.encoded_labels = self.label_encoder.fit_transform(self.annotations.iloc[:, 2].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 加载图像...\n",
    "        img_name_gaussian = os.path.join(self.root_dir_gaussian, str(self.annotations.iloc[index, -1]) + '.npy')\n",
    "        image_gaussian = np.load(img_name_gaussian).astype(np.float32)\n",
    "        if self.transform:\n",
    "            image_gaussian = self.transform(image_gaussian)\n",
    "        \n",
    "        img_name_unet = os.path.join(self.root_dir_unet, str(self.annotations.iloc[index, -1]) + '.npy')\n",
    "        image_unet = np.load(img_name_unet).astype(np.float32)\n",
    "        if self.transform:\n",
    "            image_unet = self.transform(image_unet)\n",
    "\n",
    "        # 使用已编码的标签\n",
    "        label = self.encoded_labels[index]\n",
    "        label = torch.tensor(label, dtype=torch.long)  # 转换为Tensor\n",
    "        return (image_gaussian, image_unet), label\n",
    "    \n",
    "# 定义图像转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将numpy数组转换为torch张量，并且从(H, W, C)转换为(C, H, W)且归一化到[0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
    "])\n",
    "\n",
    "class DualInputSwinTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DualInputSwinTransformer, self).__init__()\n",
    "        # 定义两个独立的Swin Transformer模型作为编码器\n",
    "        self.swin_gaussian = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=0)\n",
    "        self.swin_unet = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=0)\n",
    "        \n",
    "        # 定义一个分类器，将两个编码器的输出合并后进行分类\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 * 2, 512),  # 假设每个Swin Transformer的输出特征大小为768\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x\n",
    "        x1 = self.swin_gaussian(x1)\n",
    "        x2 = self.swin_unet(x2)\n",
    "        # 应用 6:4 的权重比例\n",
    "        weighted_x1 = x1 * 0.6\n",
    "        weighted_x2 = x2 * 0.4\n",
    "        # 在特征维度上合并加权的编码器输出\n",
    "        x = torch.cat((weighted_x1, weighted_x2), dim=1)\n",
    "        return x  # 返回特征而不是分类器的输出\n",
    "\n",
    "# 训练和评估参数\n",
    "num_epochs = 15\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 初始化数据集\n",
    "train_dataset = DualNPYDataset(csv_file='/kaggle/input/double-chanel-transformer/train.csv',\n",
    "                               root_dir_gaussian='/kaggle/input/double-chanel-transformer/transformer_gaus_train/transformer_gaus_train',\n",
    "                               root_dir_unet='/kaggle/input/double-chanel-transformer/transformer_predicted_train/transformer_predicted_train',\n",
    "                               transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = DualNPYDataset(csv_file='/kaggle/input/double-chanel-transformer/validation.csv',\n",
    "                               root_dir_gaussian='/kaggle/input/double-chanel-transformer/transformer_gaus_validation/transformer_gaus_validation',\n",
    "                               root_dir_unet='/kaggle/input/double-chanel-transformer/transformer_predicted_validation/transformer_predicted_validation',\n",
    "                               transform=transform)\n",
    "\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = DualNPYDataset(csv_file='/kaggle/input/double-chanel-transformer/test.csv',\n",
    "                               root_dir_gaussian='/kaggle/input/double-chanel-transformer/transformer_gaus_test/transformer_gaus_test',\n",
    "                               root_dir_unet='/kaggle/input/double-chanel-transformer/transformer_predicted_test/transformer_predicted_test',\n",
    "                               transform=transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 模型初始化\n",
    "num_classes = len(np.unique(train_dataset.annotations['labels']))\n",
    "model = DualInputSwinTransformer(num_classes=num_classes).to(device)\n",
    "\n",
    "# 创建一个权重数组，给第三类更高的权重\n",
    "weights = torch.tensor([1.0, 1.0, 1.0, 1.0], dtype=torch.float32).to(device)\n",
    "\n",
    "# 使用加权损失函数\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T07:11:16.116636Z",
     "iopub.status.busy": "2024-08-07T07:11:16.115842Z",
     "iopub.status.idle": "2024-08-07T07:11:16.123876Z",
     "shell.execute_reply": "2024-08-07T07:11:16.122690Z",
     "shell.execute_reply.started": "2024-08-07T07:11:16.116604Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(loader, model, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (image_gaussian, image_unet), targets in loader:\n",
    "            image_gaussian, image_unet = image_gaussian.to(device), image_unet.to(device)\n",
    "            # 提取特征\n",
    "            output = model((image_gaussian, image_unet))\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(targets.cpu().numpy())\n",
    "\n",
    "    features = np.concatenate(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T07:11:18.342051Z",
     "iopub.status.busy": "2024-08-07T07:11:18.341680Z",
     "iopub.status.idle": "2024-08-07T07:11:18.355674Z",
     "shell.execute_reply": "2024-08-07T07:11:18.354712Z",
     "shell.execute_reply.started": "2024-08-07T07:11:18.342022Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader, test_loader, criterion, optimizer, scheduler, num_epochs=15, device='cuda'):\n",
    "    model.to(device)\n",
    "    # 解冻特定层的参数\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'classifier' in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # 确保优化器仅更新requires_grad=True的参数\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for (images_gaussian, images_unet), labels in train_loader:\n",
    "            images_gaussian = images_gaussian.to(device)\n",
    "            images_unet = images_unet.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model((images_gaussian, images_unet))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # 在每个epoch结束后评估模型性能\n",
    "        train_accuracy = evaluate_model(model, train_loader, device)\n",
    "        validation_accuracy = evaluate_model(model, validation_loader, device)\n",
    "        test_accuracy = evaluate_model(model, test_loader, device)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Validation Accuracy: {validation_accuracy:.2f}%, '\n",
    "              f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "def evaluate_model(model, data_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (images_gaussian, images_unet), labels in data_loader:\n",
    "            images_gaussian = images_gaussian.to(device)\n",
    "            images_unet = images_unet.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model((images_gaussian, images_unet))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T07:13:21.447311Z",
     "iopub.status.busy": "2024-08-07T07:13:21.446880Z",
     "iopub.status.idle": "2024-08-07T07:13:21.451877Z",
     "shell.execute_reply": "2024-08-07T07:13:21.450858Z",
     "shell.execute_reply.started": "2024-08-07T07:13:21.447278Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '/kaggle/working/trained_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 验证准确率: 0.944\n",
      "SVM 测试准确率: 0.953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 提取特征\n",
    "train_features, train_labels = extract_features(train_loader, model, device)\n",
    "validation_features, validation_labels = extract_features(validation_loader, model, device)\n",
    "test_features, test_labels = extract_features(test_loader, model, device)\n",
    "\n",
    "# 训练 SVM\n",
    "svm_clf = SVC(kernel='linear', C=1, probability=True)  # 设置 probability=True 以输出概率\n",
    "svm_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 验证 SVM\n",
    "validation_predictions_svm = svm_clf.predict(validation_features)\n",
    "validation_accuracy_svm = accuracy_score(validation_labels, validation_predictions_svm)\n",
    "print(f'SVM 验证准确率: {validation_accuracy_svm:.4f}')\n",
    "\n",
    "# 测试 SVM\n",
    "test_predictions_svm = svm_clf.predict(test_features)\n",
    "test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm)\n",
    "print(f'SVM 测试准确率: {test_accuracy_svm:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 验证准确率: 0.945\n",
      "MLP 测试准确率: 0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 训练 MLP\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "mlp_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 验证 MLP\n",
    "validation_predictions_mlp = mlp_clf.predict(validation_features)\n",
    "validation_accuracy_mlp = accuracy_score(validation_labels, validation_predictions_mlp)\n",
    "print(f'MLP 验证准确率: {validation_accuracy_mlp:.4f}')\n",
    "\n",
    "# 测试 MLP\n",
    "test_predictions_mlp = mlp_clf.predict(test_features)\n",
    "test_accuracy_mlp = accuracy_score(test_labels, test_predictions_mlp)\n",
    "print(f'MLP 测试准确率: {test_accuracy_mlp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB 验证准确率: 0.942\n",
      "XGB 测试准确率: 0.936\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 转换数据为 DMatrix 格式\n",
    "dtrain = xgb.DMatrix(train_features, label=train_labels)\n",
    "dvalid = xgb.DMatrix(validation_features, label=validation_labels)\n",
    "dtest = xgb.DMatrix(test_features, label=test_labels)\n",
    "\n",
    "# 设置参数\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # 用于多分类\n",
    "    'num_class': num_classes,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# 训练 XGBoost\n",
    "xgb_clf = xgb.train(params, dtrain, num_boost_round=100, evals=[(dvalid, 'validation')])\n",
    "\n",
    "# 验证 XGBoost\n",
    "validation_predictions_xgb = xgb_clf.predict(dvalid)\n",
    "validation_accuracy_xgb = accuracy_score(validation_labels, np.argmax(validation_predictions_xgb, axis=1))\n",
    "print(f'XGBoost 验证准确率: {validation_accuracy_xgb:.4f}')\n",
    "\n",
    "# 测试 XGBoost\n",
    "test_predictions_xgb = xgb_clf.predict(dtest)\n",
    "test_accuracy_xgb = accuracy_score(test_labels, np.argmax(test_predictions_xgb, axis=1))\n",
    "print(f'XGBoost 测试准确率: {test_accuracy_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 测试准确率: 0.954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 创建 VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_clf),\n",
    "        ('mlp', mlp_clf),\n",
    "        ('xgb', xgb.XGBClassifier(objective='multi:softprob', n_estimators=100, max_depth=6, learning_rate=0.1))\n",
    "    ],\n",
    "    voting='soft',  # 使用软投票\n",
    "    weights=[1, 1, 1]  # 根据需要调整权重\n",
    ")\n",
    "\n",
    "# 训练 VotingClassifier\n",
    "voting_clf.fit(train_features, train_labels)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "test_predictions_voting = voting_clf.predict(test_features)\n",
    "\n",
    "# 计算最终准确率\n",
    "voting_accuracy = accuracy_score(test_labels, test_predictions_voting)\n",
    "print(f'Voting Classifier 测试准确率: {voting_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4695317,
     "sourceId": 7978272,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
